{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benedettoscala/ifttt-code-generator/blob/main/bart_nl2ifttt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup\n",
        "In this section, we install the necessary dependencies for the notebook. The libraries `evaluate` and `rouge_score` are installed to facilitate text evaluation, particularly for computing ROUGE scores, which are commonly used for assessing the quality of text generation models.\n",
        "\n"
      ],
      "metadata": {
        "id": "YGS9ZEtONUh1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmyuqPXtDOv5",
        "outputId": "d104a0cf-33cf-47b8-b2ab-8042d41d702b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Repository Cloning and Setup\n",
        "We clone the `ifttt-code-generator` repository from GitHub, which contains the required code for this project. After cloning, we navigate into the repository directory and pull the latest changes to ensure we have the most up-to-date version."
      ],
      "metadata": {
        "id": "YoLwrVmoNXGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benedettoscala/ifttt-code-generator\n",
        "%cd ifttt-code-generator/\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLpELkCb5Yez",
        "outputId": "766a455f-24aa-4d5e-d450-1b4cc04bd5a2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ifttt-code-generator' already exists and is not an empty directory.\n",
            "/content/ifttt-code-generator\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 428 bytes | 10.00 KiB/s, done.\n",
            "From https://github.com/benedettoscala/ifttt-code-generator\n",
            "   97e9ba9..2d027a2  main       -> origin/main\n",
            "Updating 97e9ba9..2d027a2\n",
            "Fast-forward\n",
            " nl2gpt2.ipynb | 26 \u001b[32m+++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 25 insertions(+), 1 deletion(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Processing and Tokenization\n",
        "This section of the notebook performs dataset loading, cleaning, and tokenization using the `facebook/bart-large` tokenizer.\n",
        "\n",
        "- First, the necessary libraries (`pandas`, `numpy`, `matplotlib.pyplot`, and `transformers`) are imported.\n",
        "- The `facebook/bart-large` tokenizer is loaded, and if no padding token is defined, it is set to the EOS token.\n",
        "- A dataset is loaded from a CSV file (`datasets/cleaned_and_combined.csv`), and data cleaning is applied by removing missing values and duplicate entries in the relevant columns.\n",
        "- Each sample in the dataset is tokenized separately for the description, code, and the combined text using a separator (`\\n###\\n`).\n",
        "- Token length statistics (min, max, mean, and median) are computed for the description, code, and full text.\n",
        "- Finally, a histogram is plotted to visualize the distribution of token lengths in the dataset, with a reference line at 256 tokens to help assess token length constraints.\n"
      ],
      "metadata": {
        "id": "ZmYmiuKWNZPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Imposta il checkpoint del modello (BART-large)\n",
        "model_checkpoint = \"facebook/bart-large\"\n",
        "\n",
        "# Carica il tokenizer per facebook/bart-large\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "# Se il tokenizer non ha un token di padding definito, impostalo uguale al token EOS\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Carica il dataset\n",
        "csv_path = \"datasets/cleaned_and_combined.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Rimuovi righe con valori mancanti e duplicati nelle colonne di interesse\n",
        "df.dropna(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "df.drop_duplicates(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "\n",
        "# Definisci un separatore per unire descrizione e codice\n",
        "separator = \"\\n###\\n\"\n",
        "\n",
        "# Liste per salvare le lunghezze in token\n",
        "description_lengths = []\n",
        "code_lengths = []\n",
        "combined_lengths = []\n",
        "\n",
        "# Itera su ogni esempio nel dataset\n",
        "for _, row in df.iterrows():\n",
        "    description = row[\"cleaned_description\"]\n",
        "    code = row[\"filter_code\"]\n",
        "\n",
        "    # Tokenizza la descrizione senza troncamento\n",
        "    desc_tokens = tokenizer.encode(description, truncation=False)\n",
        "    # Tokenizza il codice senza troncamento\n",
        "    code_tokens = tokenizer.encode(code, truncation=False)\n",
        "    # Tokenizza la concatenazione: descrizione + separatore + codice\n",
        "    combined_text = description + separator + code\n",
        "    combined_tokens = tokenizer.encode(combined_text, truncation=False)\n",
        "\n",
        "    # Salva le lunghezze\n",
        "    description_lengths.append(len(desc_tokens))\n",
        "    code_lengths.append(len(code_tokens))\n",
        "    combined_lengths.append(len(combined_tokens))\n",
        "\n",
        "# Funzione per stampare statistiche (min, max, media, mediana)\n",
        "def print_stats(name, lengths):\n",
        "    print(f\"Statistiche per {name}:\")\n",
        "    print(\"  Min:\", np.min(lengths))\n",
        "    print(\"  Max:\", np.max(lengths))\n",
        "    print(\"  Media:\", np.mean(lengths))\n",
        "    print(\"  Mediana:\", np.median(lengths))\n",
        "    print()\n",
        "\n",
        "print_stats(\"la descrizione\", description_lengths)\n",
        "print_stats(\"il codice\", code_lengths)\n",
        "print_stats(\"il testo completo (descrizione + codice)\", combined_lengths)\n",
        "\n",
        "# Visualizza la distribuzione della lunghezza in token del testo completo\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(combined_lengths, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(256, color='red', linestyle='dashed', linewidth=2, label=\"256 token\")\n",
        "plt.title(\"Distribuzione della lunghezza dei testi (in token) per facebook/bart-large\")\n",
        "plt.xlabel(\"Numero di token\")\n",
        "plt.ylabel(\"Frequenza\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "J-yM4u9v5KQk",
        "outputId": "e4155154-3c85-4dc0-f3dc-cfb5a72da4f2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistiche per la descrizione:\n",
            "  Min: 6\n",
            "  Max: 63\n",
            "  Media: 25.476190476190474\n",
            "  Mediana: 24.0\n",
            "\n",
            "Statistiche per il codice:\n",
            "  Min: 16\n",
            "  Max: 177\n",
            "  Media: 69.81547619047619\n",
            "  Mediana: 61.5\n",
            "\n",
            "Statistiche per il testo completo (descrizione + codice):\n",
            "  Min: 28\n",
            "  Max: 197\n",
            "  Media: 96.29166666666667\n",
            "  Mediana: 88.0\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "123qky9TDOv7"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true,
        "id": "RrEpZTnvDOv8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BartForConditionalGeneration\n",
        "from datasets import load_dataset,load_from_disk\n",
        "import torch\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXxDkkOnDOv8"
      },
      "source": [
        "### Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qG7EmiWxDOv8"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_0RpXuE52Ro",
        "outputId": "bd775115-78be-45ab-93f0-f7bb64a566fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading and Splitting\n",
        "This section of the notebook loads and processes the dataset for training and evaluation.\n",
        "\n",
        "- The dataset is loaded from a CSV file using `pandas`.\n",
        "- Data cleaning is applied by removing missing values and duplicate entries in the `cleaned_description` and `filter_code` columns.\n",
        "- The dataset is then split into training (80%) and testing (20%) subsets using `train_test_split`, ensuring reproducibility with a fixed random seed (`random_state=42`).\n",
        "- The `pandas` DataFrames are converted into Hugging Face `Dataset` objects for better compatibility with NLP models.\n",
        "- Finally, the dataset is structured into a `DatasetDict`, which organizes the training and testing sets for further processing.\n",
        "\n",
        "The number of examples in the training and test sets is printed at the end to confirm the split.\n"
      ],
      "metadata": {
        "id": "3epzzMzANcVb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yZRG7y2MDOv9"
      },
      "outputs": [],
      "source": [
        "base_path = os.getcwd()\n",
        "absolute_path = os.path.join(base_path,r'ifttt-code-generator/datasets/cleaned_and_combined.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsnlWoZFDOv9",
        "outputId": "6288eb1b-f5f6-4d5c-ecf4-ad84012be82d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 134\n",
            "Test set size: 34\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Caricamento del dataset\n",
        "csv_path = \"ifttt-code-generatordatasets/cleaned_and_combined.csv\"\n",
        "df = pd.read_csv(absolute_path)\n",
        "\n",
        "#droppa i duplicati e i valori nulli se ci sono\n",
        "df.dropna(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "df.drop_duplicates(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "\n",
        "# Suddivisione in train e test set (80%-20%)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertiamo i DataFrame in Dataset Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "dataset = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
        "\n",
        "# Stampa delle dimensioni dei set di training e test\n",
        "print(\"Train set size:\", len(dataset[\"train\"]))\n",
        "print(\"Test set size:\", len(dataset[\"test\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true,
        "id": "lYGefEPVDOv9"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"facebook/bart-large\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "trusted": true,
        "id": "zchbLUnLDOv9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4NH2VuGDOv9"
      },
      "source": [
        "### Model Tokenization and Preprocessing\n",
        "In this section, we define the tokenizer and preprocess the dataset for training.\n",
        "\n",
        "- The `facebook/bart-large` tokenizer is loaded using `AutoTokenizer.from_pretrained`.\n",
        "- We define the maximum input length (256 tokens) and target length (128 tokens) to ensure that text sequences fit within the model's constraints.\n",
        "- A prefix (`ifttt_prompt: `) is added to each description to provide context for the model.\n",
        "- The `preprocess_function` tokenizes the descriptions (`cleaned_description`) and corresponding code snippets (`filter_code`), ensuring that they respect the defined token limits and truncation settings.\n",
        "- The labels (target sequences) are tokenized separately, and their token IDs are stored within the model input structure.\n",
        "- Finally, the preprocessing function is applied to the dataset using `.map()` to tokenize all data efficiently.\n",
        "\n",
        "The progress bars at the bottom confirm that the dataset has been successfully tokenized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "trusted": true,
        "id": "LPCle05DDOv-"
      },
      "outputs": [],
      "source": [
        "max_input_length = 256\n",
        "max_target_length = 128\n",
        "prefix1 = \"ifttt_prompt: \"\n",
        "prefix2 = \" ifttt_context: \"\n",
        "\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer([prefix1 + prompt for prompt in examples['cleaned_description']],\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "    )\n",
        "    labels = tokenizer(\n",
        "        examples['filter_code'], max_length=max_target_length, truncation=True\n",
        "    )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f984dc82a70349da8b1963c91ec038a1",
            "08470a47033b4872995121b0842c01ad",
            "6283440b05ea45b789899d6b4bb4ff08",
            "b8ce0f92adbf40a5bbe421b95b2abe1c",
            "d8ea172060df4903b1eba13e0edc0430",
            "d57e89d5a7244322b699a61fd24d1bb5",
            "e5148926d6de429296c590daf1866f8d",
            "042b923160e040bc8261197476c2b4aa",
            "50bb44e8ee7246b6925f162fd6539547",
            "b05f846c171243e68d3a889efc818220",
            "11911582efe548d1aa09460d920c91c2",
            "d180341375cb49eeb61d28711ec05f71",
            "614f3b3ef68b4bbb84c4a138fc5ebc71",
            "6f5ee372130743aaaff8e8ca4a1052ea",
            "fe481de94b1e4487a1bd6845f2709d1f",
            "025e13a3fa2a4c7ea49111220ab1c7db",
            "146dc38546794240b5360a36c0a381a0",
            "a0c82245c1744d39a51a7ff844562ac6",
            "fb2c46f4600c4c03a54500bee2602fa1",
            "7ed2c97d728e4204bfa22685e3d0c4be",
            "670c0d7167184fd4ad79441cb202747b",
            "0e2dde3f97b0460ead8f0b7205c3bf15"
          ]
        },
        "id": "qWhBw7IeDOv-",
        "outputId": "6c733c6f-fedf-4724-b3da-fd851c073733"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/134 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f984dc82a70349da8b1963c91ec038a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d180341375cb49eeb61d28711ec05f71"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDOJKqGODOv-"
      },
      "source": [
        "### Evaluation Metrics Setup\n",
        "In this section, we load three commonly used evaluation metrics for text generation tasks using the `evaluate` library:\n",
        "\n",
        "- **ROUGE (Recall-Oriented Understudy for Gisting Evaluation):** Measures overlap between generated text and reference text based on n-grams and longest common subsequence. It is widely used for summarization tasks.\n",
        "- **BLEU (Bilingual Evaluation Understudy):** Computes precision-based similarity by comparing generated text with reference translations. It is commonly used in machine translation.\n",
        "- **METEOR (Metric for Evaluation of Translation with Explicit ORdering):** Improves upon BLEU by considering synonym matching, stemming, and word order to provide a more nuanced evaluation.\n",
        "\n",
        "These metrics will be used to assess the quality of model-generated text by comparing it with ground-truth references.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "trusted": true,
        "id": "dEf8DusDDOv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd2c81c-06e2-4648-ba93-ef579756e2cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "bleu_score = evaluate.load(\"bleu\")\n",
        "meteor_score = evaluate.load(\"meteor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3hUEYHODOv_"
      },
      "source": [
        "### Model Initialization\n",
        "In this section, we load and configure the model for sequence-to-sequence learning.\n",
        "\n",
        "- The `facebook/bart-large` model is loaded using `AutoModelForSeq2SeqLM.from_pretrained()`, which retrieves a pre-trained sequence-to-sequence model.\n",
        "- The generation parameters are set:\n",
        "  - `max_new_tokens = 128`: The model can generate up to 128 tokens per output.\n",
        "  - `min_new_tokens = 5`: The model must generate at least 5 tokens.\n",
        "- These settings are applied both through `generation_config` and `config` to ensure consistency.\n",
        "\n",
        "Once the model is loaded, we can use it for text generation tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "trusted": true,
        "id": "-_t1nl5ZDOv_"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "trusted": true,
        "id": "q9QIoSnIDOv_"
      },
      "outputs": [],
      "source": [
        "model.generation_config.max_new_tokens = 128\n",
        "model.generation_config.min_new_tokens = 5\n",
        "model.config.max_new_tokens = 128\n",
        "model.config.min_new_tokens = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "trusted": true,
        "id": "FfkKSghSDOv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85119459-407d-468d-edcd-4479b39ed539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BartConfig {\n",
            "  \"_attn_implementation_autoset\": true,\n",
            "  \"_name_or_path\": \"facebook/bart-large\",\n",
            "  \"activation_dropout\": 0.1,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 1024,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 4096,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 12,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 4096,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 12,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_new_tokens\": 128,\n",
            "  \"max_position_embeddings\": 1024,\n",
            "  \"min_new_tokens\": 5,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"normalize_before\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"scale_embedding\": false,\n",
            "  \"task_specific_params\": {\n",
            "    \"summarization\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 128,\n",
            "      \"min_length\": 12,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_cnn\": {\n",
            "      \"length_penalty\": 2.0,\n",
            "      \"max_length\": 142,\n",
            "      \"min_length\": 56,\n",
            "      \"num_beams\": 4\n",
            "    },\n",
            "    \"summarization_xsum\": {\n",
            "      \"length_penalty\": 1.0,\n",
            "      \"max_length\": 62,\n",
            "      \"min_length\": 11,\n",
            "      \"num_beams\": 6\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "trusted": true,
        "id": "kU5n-2NMDOv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0162cd80-fefc-490d-a1cd-60d55e084735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"early_stopping\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"forced_bos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 2,\n",
            "  \"max_new_tokens\": 128,\n",
            "  \"min_new_tokens\": 5,\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.generation_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tO0tygyDOv_"
      },
      "source": [
        "\n",
        "### Data Collator\n",
        "This section prepares the data for training by using a data collator.\n",
        "\n",
        "- `DataCollatorForSeq2Seq` is initialized with the tokenizer and model to dynamically pad inputs to the longest sequence in a batch, improving computational efficiency.\n",
        "- Unnecessary columns from the tokenized dataset are removed to ensure compatibility with the model.\n",
        "- A sample batch of two training examples is processed through the data collator, demonstrating the transformation into tensor format.\n",
        "\n",
        "The data collator ensures that input sequences are properly formatted and padded for efficient batch processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "trusted": true,
        "id": "IJxfCBaMDOv_"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "trusted": true,
        "id": "1VFfkqUNDOv_"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns(dataset[\"train\"].column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "trusted": true,
        "id": "-msE9xhWDOv_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c994098f-7512-4d83-a571-46c3fc1e56cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0,  1594,  5967,    90,  1215, 12501,  3320,    35, 10683,  2512,\n",
              "            10,  7127,   515,     7,  8736,    47,     7,   244,   110,  4716,\n",
              "          3042,    49,  1940,  1175,     4,     2,     1,     1,     1],\n",
              "        [    0,  1594,  5967,    90,  1215, 12501,  3320,    35,   318,   821,\n",
              "         11762,    34,    41,   515,  1440,    22, 21461,   113,   278,     5,\n",
              "         19722,  2413,  1942,     7,   409,   454,  3868,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1]]), 'labels': tensor([[    0, 10806,  1946,  5457, 37622,     4, 45043, 14699,     4,  4509,\n",
              "         43048,  1437, 15747,  2289,  5457, 37622,     4, 45043, 14699,     4,\n",
              "          4530, 43048,  1437, 15747,    86, 40215,  5457,   706,  1437,  1437,\n",
              "          1437,   114,  1640,  4509,   207,   958, 40215,  8061,   321, 48200,\n",
              "          2289,   207,   996,  8061,   321,    43,  1437,  1437,  1437,  1204,\n",
              "         15117, 29702,     4, 35356, 20763, 44879,     4, 46554, 43048,     2],\n",
              "        [    0,  1594,    36, 20441, 15117, 29702,     4, 21680,  7605, 39954,\n",
              "          5320,  7870,     4, 46525,     4,   560,   791,  5961, 38834, 43048,\n",
              "         49333,    22, 45213,  8070, 25522,  1437,  1437, 19722,  2413,  1942,\n",
              "             4, 36695, 19192, 19163,  7469,     4, 46554, 43048, 35524,     2,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]]), 'decoder_input_ids': tensor([[    2,     0, 10806,  1946,  5457, 37622,     4, 45043, 14699,     4,\n",
              "          4509, 43048,  1437, 15747,  2289,  5457, 37622,     4, 45043, 14699,\n",
              "             4,  4530, 43048,  1437, 15747,    86, 40215,  5457,   706,  1437,\n",
              "          1437,  1437,   114,  1640,  4509,   207,   958, 40215,  8061,   321,\n",
              "         48200,  2289,   207,   996,  8061,   321,    43,  1437,  1437,  1437,\n",
              "          1204, 15117, 29702,     4, 35356, 20763, 44879,     4, 46554, 43048],\n",
              "        [    2,     0,  1594,    36, 20441, 15117, 29702,     4, 21680,  7605,\n",
              "         39954,  5320,  7870,     4, 46525,     4,   560,   791,  5961, 38834,\n",
              "         43048, 49333,    22, 45213,  8070, 25522,  1437,  1437, 19722,  2413,\n",
              "          1942,     4, 36695, 19192, 19163,  7469,     4, 46554, 43048, 35524,\n",
              "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "features = [tokenized_datasets[\"train\"][i] for i in range(2)]\n",
        "data_collator(features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_87c9chDOwA"
      },
      "source": [
        "#### Post Processing for ROUGE computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "trusted": true,
        "id": "a8anZrBlDOwA"
      },
      "outputs": [],
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "JVbxqJ5lJzMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67c99c7-0e87-47e8-9ee8-1d22cdb6d3f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DA_JmzDOwA"
      },
      "source": [
        "### Training and Evaluation Loop\n",
        "This section defines the main training and evaluation loop for the model.\n",
        "\n",
        "#### **Training Process**\n",
        "- The model is set to training mode (`model.train()`).\n",
        "- The loss is tracked for each batch, and backpropagation is performed using `accelerator.backward(loss)`.\n",
        "- The optimizer updates the model parameters, and the learning rate scheduler is stepped to adjust the learning rate.\n",
        "- The average training loss per epoch is computed and stored for visualization.\n",
        "\n",
        "#### **Evaluation Process**\n",
        "- The model is switched to evaluation mode (`model.eval()`), and no gradients are computed during inference.\n",
        "- The model generates predictions for the test dataset.\n",
        "- Predictions and reference labels are padded across processes to ensure consistency.\n",
        "- The predictions and labels are decoded into human-readable text using the tokenizer.\n",
        "- Text cleaning (`postprocess_text`) is applied to standardize predictions and references.\n",
        "\n",
        "#### **Metric Computation**\n",
        "- The `ROUGE`, `BLEU`, and `METEOR` scores are computed to evaluate the quality of generated text:\n",
        "  - **ROUGE** measures n-gram and sequence overlap between predictions and references.\n",
        "  - **BLEU** calculates the precision of generated words against references.\n",
        "  - **METEOR** considers stemming, synonyms, and word order for evaluation.\n",
        "- The final results are printed at the end of each epoch.\n",
        "\n",
        "#### **Model Saving**\n",
        "- The model's state is saved at the end of each epoch using `save_pretrained(output_dir)`.\n",
        "- The tokenizer is also saved to ensure consistency when reloading the model.\n",
        "- `accelerator.wait_for_everyone()` ensures synchronization in distributed training.\n",
        "\n",
        "This setup allows for efficient training, evaluation, and saving of the model at each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Co8kdr1fQTb",
        "outputId": "6fbac0b7-6c6b-4297-d52c-641617823581"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_MVfNXhfZv5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "trusted": true,
        "id": "uodurTu0DOwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f91dbbf5-316e-4dd0-a98f-1ebf03d4e209"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-24-1583201e3ec7>:73: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [340/340 07:10, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Meteor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>5.853900</td>\n",
              "      <td>2.514400</td>\n",
              "      <td>31.653900</td>\n",
              "      <td>17.201000</td>\n",
              "      <td>30.152100</td>\n",
              "      <td>30.166100</td>\n",
              "      <td>12.160000</td>\n",
              "      <td>27.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.337100</td>\n",
              "      <td>1.909501</td>\n",
              "      <td>32.526500</td>\n",
              "      <td>13.653600</td>\n",
              "      <td>29.689900</td>\n",
              "      <td>29.884100</td>\n",
              "      <td>20.030000</td>\n",
              "      <td>35.330000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.718000</td>\n",
              "      <td>1.730441</td>\n",
              "      <td>36.999400</td>\n",
              "      <td>22.198100</td>\n",
              "      <td>35.497600</td>\n",
              "      <td>35.490400</td>\n",
              "      <td>19.690000</td>\n",
              "      <td>33.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.438000</td>\n",
              "      <td>1.600453</td>\n",
              "      <td>36.530500</td>\n",
              "      <td>23.258900</td>\n",
              "      <td>35.371400</td>\n",
              "      <td>35.448100</td>\n",
              "      <td>21.340000</td>\n",
              "      <td>36.690000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.166500</td>\n",
              "      <td>1.550743</td>\n",
              "      <td>36.294600</td>\n",
              "      <td>21.960400</td>\n",
              "      <td>35.022900</td>\n",
              "      <td>35.005100</td>\n",
              "      <td>21.320000</td>\n",
              "      <td>35.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.068700</td>\n",
              "      <td>1.477315</td>\n",
              "      <td>36.897600</td>\n",
              "      <td>21.497200</td>\n",
              "      <td>35.337600</td>\n",
              "      <td>35.363500</td>\n",
              "      <td>21.590000</td>\n",
              "      <td>35.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.876000</td>\n",
              "      <td>1.557384</td>\n",
              "      <td>40.795900</td>\n",
              "      <td>27.058400</td>\n",
              "      <td>39.284100</td>\n",
              "      <td>39.445700</td>\n",
              "      <td>27.160000</td>\n",
              "      <td>39.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.739800</td>\n",
              "      <td>1.469411</td>\n",
              "      <td>36.258100</td>\n",
              "      <td>22.057700</td>\n",
              "      <td>35.008100</td>\n",
              "      <td>35.078800</td>\n",
              "      <td>22.550000</td>\n",
              "      <td>36.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.635600</td>\n",
              "      <td>1.480877</td>\n",
              "      <td>40.724500</td>\n",
              "      <td>25.992300</td>\n",
              "      <td>38.724100</td>\n",
              "      <td>38.698500</td>\n",
              "      <td>22.540000</td>\n",
              "      <td>35.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.564400</td>\n",
              "      <td>1.475681</td>\n",
              "      <td>38.133300</td>\n",
              "      <td>23.342200</td>\n",
              "      <td>36.313900</td>\n",
              "      <td>36.429700</td>\n",
              "      <td>24.070000</td>\n",
              "      <td>36.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.512100</td>\n",
              "      <td>1.519475</td>\n",
              "      <td>48.619000</td>\n",
              "      <td>33.591100</td>\n",
              "      <td>45.931600</td>\n",
              "      <td>46.036200</td>\n",
              "      <td>36.440000</td>\n",
              "      <td>46.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>1.524732</td>\n",
              "      <td>47.390900</td>\n",
              "      <td>31.040000</td>\n",
              "      <td>45.182700</td>\n",
              "      <td>45.036700</td>\n",
              "      <td>30.270000</td>\n",
              "      <td>42.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.414200</td>\n",
              "      <td>1.534786</td>\n",
              "      <td>44.456900</td>\n",
              "      <td>29.939500</td>\n",
              "      <td>42.950400</td>\n",
              "      <td>43.093400</td>\n",
              "      <td>26.450000</td>\n",
              "      <td>40.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.344800</td>\n",
              "      <td>1.559657</td>\n",
              "      <td>49.390300</td>\n",
              "      <td>35.951300</td>\n",
              "      <td>48.635700</td>\n",
              "      <td>48.408800</td>\n",
              "      <td>35.900000</td>\n",
              "      <td>45.900000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>1.583746</td>\n",
              "      <td>47.452900</td>\n",
              "      <td>31.581900</td>\n",
              "      <td>45.374800</td>\n",
              "      <td>45.350400</td>\n",
              "      <td>32.050000</td>\n",
              "      <td>41.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.301200</td>\n",
              "      <td>1.581244</td>\n",
              "      <td>49.162200</td>\n",
              "      <td>33.553000</td>\n",
              "      <td>46.739700</td>\n",
              "      <td>46.415000</td>\n",
              "      <td>34.890000</td>\n",
              "      <td>45.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.284700</td>\n",
              "      <td>1.585290</td>\n",
              "      <td>42.081600</td>\n",
              "      <td>27.187200</td>\n",
              "      <td>40.956600</td>\n",
              "      <td>40.827200</td>\n",
              "      <td>27.480000</td>\n",
              "      <td>41.970000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.258000</td>\n",
              "      <td>1.607109</td>\n",
              "      <td>51.919700</td>\n",
              "      <td>37.240400</td>\n",
              "      <td>49.077800</td>\n",
              "      <td>48.999900</td>\n",
              "      <td>38.070000</td>\n",
              "      <td>47.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.247700</td>\n",
              "      <td>1.622380</td>\n",
              "      <td>50.838300</td>\n",
              "      <td>36.020200</td>\n",
              "      <td>48.659200</td>\n",
              "      <td>48.434400</td>\n",
              "      <td>38.600000</td>\n",
              "      <td>46.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.230900</td>\n",
              "      <td>1.629091</td>\n",
              "      <td>50.131600</td>\n",
              "      <td>34.626700</td>\n",
              "      <td>48.033200</td>\n",
              "      <td>47.835600</td>\n",
              "      <td>37.210000</td>\n",
              "      <td>46.440000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=340, training_loss=0.9901231106589822, metrics={'train_runtime': 430.9299, 'train_samples_per_second': 6.219, 'train_steps_per_second': 0.789, 'total_flos': 279052811157504.0, 'train_loss': 0.9901231106589822, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Carica le metriche\n",
        "rouge_score = evaluate.load(\"rouge\")\n",
        "bleu_score = evaluate.load(\"bleu\")\n",
        "meteor_score = evaluate.load(\"meteor\")\n",
        "\n",
        "num_train_epochs = 20\n",
        "\n",
        "# Funzione per la generazione e la valutazione delle metriche\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # Se predictions  un tuple, prendi il primo elemento\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "\n",
        "    # Converte in numpy array se necessario\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "    # Se predictions  una lista nidificata, appiattiscila\n",
        "    predictions = np.array(predictions)\n",
        "\n",
        "    # Rimpiazza -100 nei labels con tokenizer.pad_token_id\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "\n",
        "    # Decodifica delle predizioni e delle etichette\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Rimozione di spazi inutili\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Calcolo delle metriche\n",
        "    rouge_results = rouge_score.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    bleu_results = bleu_score.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    meteor_results = meteor_score.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "\n",
        "    # Normalizza i valori delle metriche\n",
        "    rouge_results = {k: round(v * 100, 4) for k, v in rouge_results.items()}\n",
        "    bleu_results = round(bleu_results[\"bleu\"] * 100, 2)\n",
        "    meteor_results = round(meteor_results[\"meteor\"] * 100, 2)\n",
        "\n",
        "    return {\n",
        "        **rouge_results,\n",
        "        \"bleu\": bleu_results,\n",
        "        \"meteor\": meteor_results\n",
        "    }\n",
        "\n",
        "# Definizione degli argomenti di training\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/Shareddrives/NLPMODELS/nl2sql_bart_final\",\n",
        "    evaluation_strategy=\"epoch\",  # Valutazione dopo ogni epoca\n",
        "    logging_strategy=\"epoch\",\n",
        "    #save_strategy=\"epoch\",  # Salvataggio automatico ogni epoca\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    #save_total_limit=2,  # Mantiene solo gli ultimi due checkpoint\n",
        "    fp16=torch.cuda.is_available(),  # Usa FP16 se disponibile\n",
        "    report_to=\"none\",  # Evita di inviare log a sistemi di tracking\n",
        "    predict_with_generate=True,  # Usa generate() durante l'inferenza\n",
        "    remove_unused_columns=True\n",
        ")\n",
        "\n",
        "# Creazione del Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],  # Usa dataset invece di dataloader\n",
        "    eval_dataset=tokenized_datasets['test'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Avvio del training\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: evaluate the model on the test set\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "results = trainer.evaluate()\n",
        "results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "JDL4iJMBeNZj",
        "outputId": "6dbde6fd-2ff3-4ef2-8bb4-46d9d7ef3178"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:21]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 1.6290912628173828,\n",
              " 'eval_rouge1': 50.1316,\n",
              " 'eval_rouge2': 34.6267,\n",
              " 'eval_rougeL': 48.0332,\n",
              " 'eval_rougeLsum': 47.8356,\n",
              " 'eval_bleu': 37.21,\n",
              " 'eval_meteor': 46.44,\n",
              " 'eval_runtime': 28.2977,\n",
              " 'eval_samples_per_second': 1.202,\n",
              " 'eval_steps_per_second': 0.177,\n",
              " 'epoch': 20.0}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference with Text-to-Text Pipeline\n",
        "In this section, we load the trained model and use it for text generation.\n",
        "\n",
        "#### **Model Loading**\n",
        "- The trained model is loaded from the specified checkpoint directory (`nl2sql_epoch30`).\n",
        "- The `pipeline` function from `transformers` is used to create a text-to-text generation pipeline.\n",
        "- Both the model and tokenizer are loaded from the same checkpoint to ensure compatibility.\n",
        "\n",
        "#### **Generating Predictions**\n",
        "- A sample prompt is provided to the model:  \n",
        "  `\"ifttt prompt: Create an applet that saves new photos from my phone to a Google Drive folder automatically\"`\n",
        "- The model generates a text-based response using `pipeline(\"text2text-generation\")`.\n",
        "- The generated output is limited to a maximum of 128 tokens.\n",
        "\n",
        "#### **Usage**\n",
        "- This pipeline allows the model to generate structured text based on natural language prompts.\n",
        "- It can be used to create IFTTT-like (If This Then That) automation rules based on textual descriptions.\n",
        "\n",
        "This setup enables efficient inference, allowing the model to process user inputs and generate corresponding automation rules.\n"
      ],
      "metadata": {
        "id": "U5jE2a89OI-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "model_path = \"nl2sql_bart/checkpoint-170\"\n",
        "\n",
        "# Load the pipeline\n",
        "generator = pipeline(\"text2text-generation\", model=model_path, tokenizer=model_path)\n",
        "\n",
        "# Example usage\n",
        "prompt = \"ifttt prompt: Create an applet that Save new photos from my phone to a Google Drive folder automatically\"\n",
        "result = generator(prompt, max_length=128)\n",
        "\n",
        "result"
      ],
      "metadata": {
        "id": "B0NaB-lEIDH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3edff099-abb3-4e9a-dbbc-b7bccf3d8c3e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'var title = Trigger.EntryTitle var keyword1 = \\'Photo\\'  if (title.indexOf(keyword1) < 0) {   GoogleDrive.createPhotoFolder.skip(\"Not related to me\") }'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: iterate on the test sets and generate a code for every prompt and print the generated code  with the actual code in the test set\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_path = \"nl2sql_bart/checkpoint-340\"\n",
        "generator = pipeline(\"text2text-generation\", model=model_path, tokenizer=model_path)\n",
        "\n",
        "#load the dataset and split it with random state 42\n",
        "df = pd.read_csv(\"ifttt-code-generator/datasets/cleaned_and_combined.csv\")\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Iterate over the test set prompts\n",
        "for index, row in test_df.iterrows():\n",
        "    prompt = test_df.loc[index, \"cleaned_description\"]\n",
        "    actual_code = test_df.loc[index, \"filter_code\"]\n",
        "\n",
        "    # Generate code using the model\n",
        "    generated_code_result = generator(f\"ifttt_prompt: {prompt}\", max_length=128)\n",
        "    generated_code = generated_code_result[0][\"generated_text\"]\n",
        "\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Generated Code:\\n{generated_code}\")\n",
        "    print(f\"Actual Code:\\n{actual_code}\")\n",
        "    print(\"-\" * 50) # Separator between examples\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96oz3bw-bovu",
        "outputId": "f9737dfe-6c7b-4b80-ed19-c4cd85da4a8a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet will append Medium bookmarks to a stream in a data.world dataset.\n",
            "Generated Code:\n",
            "const pairs = Object.getOwnPropertyNames(Twitter.newTweetByUser.Text).map(prop => prop + \"Medium\" + tweet[prop]) Datadotworld.append.setPayload(pairs.join(\"Medium\")\n",
            "Actual Code:\n",
            "const bookmark = (Medium.postBookmarkedByYou as any) const pairs = Object.getOwnPropertyNames(bookmark).map(prop => prop + \"||\" + bookmark[prop]) Datadotworld.append.setPayload(pairs.join(\"|||\"))\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: If Netatmo weather station reports rain amount for yesterday exceeding 5mm (0.2inch), do not water my yard for today.\n",
            "Generated Code:\n",
            "if(parseFloat(Netatmo.rainYesterdayAmount.MeasuredRainfallMM)<5){   Netro.noWater.skip() }\n",
            "Actual Code:\n",
            "if(parseFloat(Netatmo.rainYesterdayAmount.MeasuredRainfallMM)<5){   Netro.noWater.skip() }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: When a specific user posts a tweet that has a URL in it, this Applet will save that URL to Pocket with the \"IFTTT\" tag.\n",
            "Generated Code:\n",
            "var tweet = Twitter.newTweetByUser.Text;  var regex = /https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+.~#=]{1,2,3,4,5,6,7,8,9,10,12,15,16,17,19,19];   Pocket.readItLater.setUrl(url); }\n",
            "Actual Code:\n",
            "var tweet = Twitter.newTweetByUser.Text;  var regex = /https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&  var match = tweet.match(regex);  if (match) {   Pocket.readItLater.setUrl(match[0]); } else {   Pocket.readItLater.skip(\"No URL\"); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: When tomorrow's forecast has a low temperature of 40F to 50F, add an all-day calendar event mentioning which drawer to get dressed from.\n",
            "Generated Code:\n",
            "if (parseInt(Weather.tomorrowsWeatherAtTime.LowTempFahrenheit) < 40) {   GoogleCalendar.addDetailedEvent.skip(); }\n",
            "Actual Code:\n",
            "if (parseInt(Weather.tomorrowsWeatherAtTime.LowTempFahrenheit) < 40) {   GoogleCalendar.addDetailedEvent.skip(); }  if (parseInt(Weather.tomorrowsWeatherAtTime.LowTempFahrenheit) > 50) {   GoogleCalendar.addDetailedEvent.skip(); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Set a Yeelight Scene on exiting an area between 6am and 6pm (06:00 - 17:59)\n",
            "Generated Code:\n",
            "if (Meta.currentUserTime.hour() >= 18 || Meta.currentTime.minute() < 6) {   Yeelight.setScene.skip('Too Late'); }\n",
            "Actual Code:\n",
            "if (Meta.currentUserTime.hour() >= 18 || Meta.currentUserTime.hour() < 6) {   Yeelight.setScene.skip('Too Late'); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: If Boundary Alarm is disarmed and it is nighttime turn on chosen Philips Hue lights (e.g. entry route lights)\n",
            "Generated Code:\n",
            "var season = Meta.currentUserTime.month(); var sunrises = [ 7, 8, 9, 10, 12, 14, 16, 18, 19, 20, 20 ]; var sunsets   = [ 19, 21, 22, 24, 24 ];  var hour = Meta[0];  if (hour >= sunrises[season] && hour <= sunsets[season]) {   Hue.turnOnAllHue.skip(); }\n",
            "Actual Code:\n",
            "var season = Meta.currentUserTime.month();  var sunrises = [ 9,  8,  7,  7,  6,  5,  5,  6,  7,  8,  8,  9 ]; var sunsets  = [ 15, 16, 17, 19, 20, 21, 21, 20, 19, 18, 16, 15 ];  var hour = Meta.currentUserTime.hour();   if (hour >= sunrises[season] && hour <= sunsets[season]) {   Hue.turnOnAllHue.skip(); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Which ever color tier your latest Super Chat message is, your Hue lights will change to match that color!\n",
            "Generated Code:\n",
            "if (Youtube.newSuperchat.ColorTier == \"Light blue\") {   Hue.setColorAllHue.setBrightness(\"#0092ff\") }\n",
            "Actual Code:\n",
            "if (Youtube.newSuperchat.ColorTier == \"Light blue\")   {Hue.setColorAllHue.setColor(\"#0092ff\")} if (Youtube.newSuperchat.ColorTier == \"Blue\")   {Hue.setColorAllHue.setColor(\"#4148b2\")}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Send an SMS message when the Link collar is charged.\n",
            "Generated Code:\n",
            "var minute = Meta.triggerTime.minute()  var minuteString = minute.toString()    if(minute%30 > 0 && minute%10 > 0 )   Sms.sendMeText.skip()\n",
            "Actual Code:\n",
            "var minute = Meta.triggerTime.minute()  var minuteString = minute.toString()  var runday = Meta.triggerTime.day()  var currentdate = new Date(LinkMyPet.collarInfo.CreatedAt).getDay()    var batteryAmount =  parseInt(LinkMyPet.collarInfo.Battery, 10);  if(minute%30 > 0 && batteryAmount < 100 || (currentdate != runday) )    Sms.sendMeText.skip()\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: We have your date night planned ahead of time, just tell us where and what day works for you! Impress your significant other every week with a new plan.\n",
            "Generated Code:\n",
            "let optionOne = Math.floor((Math.random() * Trakt.recommendedMovies.length)) let optionTwo = Yelp.searchBusiness.length(optionOne).toLowerCase() let optionThree = GoogleSheets.addDetailedSearch(optionTwo).setTitle(optionThree).setPhoto(optionFour).setLocation(optionFive)\n",
            "Actual Code:\n",
            "let optionOne = Math.floor((Math.random() * Trakt.recommendedMovies.length)) let optionTwo = Math.floor((Math.random() * Yelp.searchBusiness.length)) Email.sendMeEmail.setSubject(`It's night date night!`) Email.sendMeEmail.setBody(`Tonight you should watch ${Trakt.recommendedMovies[optionOne].MovieTitle}, and order dinner from ${Yelp.searchBusiness[optionTwo].BusinessName}! `)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet will save 1p for every 10 metres you cycle or run using Strava.\n",
            "Generated Code:\n",
            "var distance = parseInt(Strava.newActivityByYou.DistanceMeters); var amount = distance/1000; Monzo.potDeposit.setAmount(amount.toFixed(2));\n",
            "Actual Code:\n",
            "var distance = parseInt(Strava.newActivityByYou.DistanceMeters); var amount = distance/1000; Monzo.potDeposit.setAmount(amount.toFixed(2));\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet appends new favorite Tweets to a stream in a data.world dataset.\n",
            "Generated Code:\n",
            "const tweet = (Twitter.newFavoriteTweet as any) const pairs = Object.getOwnPropertyNames(Twitter. newFavoriteTweet).map(prop => prop + \"||\" + tweet[prop]) Datadotworld.append.setPayload(pairs.join(\"|||\"))\n",
            "Actual Code:\n",
            "const tweet = (Twitter.newFavoriteTweet as any) const pairs = Object.getOwnPropertyNames(Twitter.newFavoriteTweet).map(prop => prop + \"||\" + tweet[prop]) Datadotworld.append.setPayload(pairs.join(\"|||\"))\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Report yesterday's rainfall measurement from your Netatmo device to Netro. Netro will use it to update schedules.\n",
            "Generated Code:\n",
            "if (parseFloat(Netatmo.rainYesterday.MeasuredRainfall.Amount)<2) {   Netro.setWeather.skip(); }\n",
            "Actual Code:\n",
            "Netro.reportWeather.setDate(Netatmo.rainYesterdayAmount.MeasuredAt) Netro.reportWeather.setRain(Netatmo.rainYesterdayAmount.MeasuredRainfallMM) Netro.reportWeather.setRainProb(\"100\")\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Whenever you come home, this Applet turns on your Govee lights unless it's currently sunny.\n",
            "Generated Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment();  let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise);  let beforeSunset {    Govee.turnOnAllHue.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "Actual Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(Weather.currentWeather[0].SunsetAt); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentTime.isBefore(sunset);  if (afterSunrise && beforeSunset) {    Govee.lightBrightness.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Enter your home address on the map and when you enter the radius your Hue lights will turn on, unless it's still light outside!\n",
            "Generated Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentWeather.isBefore(sunset);  if (afterSunrise && beforeSunSet) {    Hue.turnOnAllHue.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "Actual Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(Weather.currentWeather[0].SunsetAt); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentTime.isBefore(sunset);  if (afterSunrise && beforeSunset) {    Hue.turnOnAllHue.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Used to automatically post files from a specific Google Drive folder into a Slack channel of your choosing.\n",
            "Generated Code:\n",
            "var title = Trigger.Filename;   if (title.toLowerCase().indexOf(keyword) < 0) {   Slack.postToChannel.skip('Temp File Was Skipped') }\n",
            "Actual Code:\n",
            "if (Trigger.Filename.match(/~\\$/i)) {  Slack.postToChannel.skip('Temp File Was Skipped')  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Whenever you come home, turn on your lights automatically unless it's currently sunny outside.\n",
            "Generated Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentWeather.isBefore(sunset);  if (afterSunrise && beforeSunSet) {    Magichue.poweron.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "Actual Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(Weather.currentWeather[0].SunsetAt); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentTime.isBefore(sunset);  if (afterSunrise && beforeSunset) {    Magichue.poweron.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Your phone will be called with the specified message if Arlo detects motion, but only after 9pm and until 8am.\n",
            "Generated Code:\n",
            "var hour = Meta.triggerTime.hour()  if (hour > 8 && hour < 21) {   PhoneCall.callMyPhone.skip(\"Too late\") }\n",
            "Actual Code:\n",
            "var hour = Meta.triggerTime.hour(); if (hour > 8 && hour < 21) {   PhoneCall.callMyPhone.skip(); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Twitter every time LumanyGameplay publishes a new video containing the word fantasy in the title\n",
            "Generated Code:\n",
            "let title=Youtube.newPublicVideoFromSubscriptions.Title; if(title.toUpperCase().indexOf(\"FANTASY\") ==-1){   Twitter.postNewTweet.skip(\"Not Contains the word\"+title+\"in the title\"); }\n",
            "Actual Code:\n",
            "let title=Youtube.newPublicVideoFromSubscriptions.Title; if(title.toUpperCase().indexOf(\"FANTASY\") ==-1){   Twitter.postNewTweet.skip(\"Not Contains the word\"+title+\"in the title\"); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: When spending on entertainment, take the amount from a Pot of your choosing\n",
            "Generated Code:\n",
            "if ( Monzo.cardPurchase.Category == \"Entertainment\" ) {    if (Monzo.potWithdraw.Amount.toUpperCase() < 0) { (\"Not an Entertainment Purchase\")   } else {  }\n",
            "Actual Code:\n",
            "if ( Monzo.cardPurchase.Category == \"Entertainment\" ) {    Monzo.potWithdraw.setAmount(Monzo.cardPurchase.AmountInAccountCurrency)  } else {    Monzo.potWithdraw.skip(\"Not an Entertainment Purchase\")  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: When tomorrow's forecast has a low temperature of 40F to 50F, add an all-day calendar event mentioning which drawer to get dressed from.\n",
            "Generated Code:\n",
            "if (parseInt(Weather.tomorrowsWeatherAtTime.LowTempFahrenheit) < 40) {   GoogleCalendar.addDetailedEvent.skip(); }\n",
            "Actual Code:\n",
            "if (parseInt(Weather.tomorrowsWeatherAtTime.LowTempFahrenheit) < 40) {   GoogleCalendar.addDetailedEvent.skip(); }  if (parseInt(Weather.tomorrowsWeatherAtTime.LowTempFahrenheit) > 50) {   GoogleCalendar.addDetailedEvent.skip(); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Turn on Wemo Switch After Garage Door Opens (After 5pm). Uses MyQ to detect garage door open and if it's after 5pm it will turn on Wemo switch; otherwise, it won't do anything.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour()  if (timeOfDay > 19 || timeofDay < 5) {    WemoSwitch.attributeOnDiscrete.skip()  }\n",
            "Actual Code:\n",
            "var hour     = Meta.currentUserTime.hour() if (hour < 17) {   WemoSwitch.attributeSocketOnDiscrete.skip(\"not in hour timing\") }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This Applet will send you and email when a DART rider alert goes out during weekday commuting hours (7-10am and 5-7pm).\n",
            "Generated Code:\n",
            "var Hour = Meta.currentUserTime.hour() var Day    Hour <7 || (Hour > 10 && Hour < 17) || Hour > 19) {   IfNotifications.sendNotification.skip(\"Outside of commuting hours\") }   if (Day == 6 || Day == 7){   Email.sendMeEmail.skip('Not a weekday') }\n",
            "Actual Code:\n",
            "var Hour = Meta.currentUserTime.hour() var Day = Meta.currentUserTime.day()   if (Hour <7 || (Hour > 10 && Hour < 17) || Hour > 19) {   Email.sendMeEmail.skip(\"Outside of commuting hours\") }   if (Day == 6 || Day == 7) {   Email.sendMeEmail.skip(\"Not a weekday\") }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Twitter every time The_DannyCraft publishs a new video containing the word fantasy in the title\n",
            "Generated Code:\n",
            "let title=Youtube.newPublicVideoFromSubscriptions.Title; if(title.toUpperCase().indexOf(\"FANTASY\") ==-1){   Twitter.postNewTweet.skip(\"Not Contains the word\"+title+\"in the title\"); }\n",
            "Actual Code:\n",
            "let title=Youtube.newPublicVideoFromSubscriptions.Title; if(title.toUpperCase().indexOf(\"FANTASY\") ==-1){   Twitter.postNewTweet.skip(\"Not Contains the word\"+title+\"in the title\"); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet will send your robot back to the dock when you get home after 5pm.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour()  if (timeOfDay > 17 || timeOfNight < 5) {    IfNotifications.sendNotification.skip(\"Outside of commuting hours\") }\n",
            "Actual Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();    if (timeOfDay > 0 && timeOfDay < 17) {    Irobot.dockRobot.skip()  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: ifttjx6TX3gy: New article in folder News > email\n",
            "Generated Code:\n",
            "var hour = Meta.currentUserTime.hour()    if(hour<8 || hour>=21 || hour<9) {   Email.sendMeEmail.skip()  }\n",
            "Actual Code:\n",
            "var hour = Meta.currentUserTime.hour()  var wday = Meta.currentUserTime.format('dddd').toLowerCase()    if(hour<8 || hour>=21 || (!wday.match(\"sat\") && !wday.match(\"sun\") && hour>=9 && hour<17) || (wday.match(\"fri\") && hour>=17 && hour<19) || ((wday.match(\"sat\") || wday.match(\"sun\")) && hour<12)){    Email.sendMeEmail.skip()  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: facebook only text post\n",
            "Generated Code:\n",
            "var text = Facebook.newStatusMessageByPage.Text.replace(/(https?:\\/\\/\\S+)/g, '|||' + text);  var subStr = Meta.currentUserTime.hour()   if(text.length > 115) {    subStr += \"|||\" + subStr;  }\n",
            "Actual Code:\n",
            "Facebook.newStatusMessageByYou.From Facebook.newStatusMessageByYou.Message Facebook.newStatusMessageByYou.UpdatedAt\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Sleep peacefully knowing you will receive a phone call alert if your door is opened during sleeping hours (10pm to 6am).\n",
            "Generated Code:\n",
            "var hour = Meta.currentUserTime.hour()  if (hour < 22 && hour > 6) {   PhoneCall.callMyPhone.skip(\"Not during sleeping hours\") }\n",
            "Actual Code:\n",
            "var hour = Meta.currentUserTime.hour()  if (hour < 22 && hour > 6) {   PhoneCall.callMyPhone.skip(\"Not during sleeping hours\") }  else{  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Videos of YouTube subscriptions to Todoist - links open in ProTube\n",
            "Generated Code:\n",
            "var url = url.replace(/(Youtube.newPublicVideoFromSubscriptions.Url);  var ID = url;    if(url.indexOf(\"https:\n",
            "Actual Code:\n",
            "var url;    url=Youtube.newPublicVideoFromSubscriptions.Url  var ID;    url = url.replace(/(>|<)/gi,'').split(/(vi\\/|v=|\\/v\\/|youtu\\.be\\/|\\/embed\\/)/);    if(url[2] !== undefined) {      ID = url[2].split(/[^0-9a-z_\\-]/i);      ID = ID[0];    }    else {      ID = url;    }    Todoist.createTask.setTaskContent(\"pt2:\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This will automatically turn on the WiZ light(s) of your choice when you enter the area you have defined, unless it's currently sunny outside.\n",
            "Generated Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentWeather.isBefore(sunset);  if (afterSunrise && beforeSunSet) {    WiZLighting.attributeLsOnDiscrete.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "Actual Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(Weather.currentWeather[0].SunsetAt); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentTime.isBefore(sunset);  if (afterSunrise && beforeSunset) {    Wiz.turnOn.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: The app sends you notifications for stories by The verge, between 8 Am and 11 PM and saves stories to Feedly during silent hours.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();    if (timeOfDay > 22 || timeOfNight < 8 ) {   IfNotifications.sendNotification.skip(\"Too late; saving to Feedly\");  }\n",
            "Actual Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();    if (timeOfDay > 22 || timeOfDay < 8) {    IfNotifications.sendNotification.skip(\"Too late; saving to Feedly\");  } else {    Feedly.createNewEntryFeedly.skip(\"Sending notification instead\");  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: If gcal has an event named \"Work\" set the Ecobee to away until transition.\n",
            "Generated Code:\n",
            "if (GoogleCalendar.eventFromSearchStarts.Title.toUpperCase() != \"WORK\") {   Ecobee.climateNextTransition.skip() }\n",
            "Actual Code:\n",
            "if (GoogleCalendar.eventFromSearchStarts.Title.toUpperCase() != \"WORK\") {   Ecobee.climateNextTransition.skip() }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This Applet posts to a Slack channel when there's a service alert on Rapid Ride D line between the hours of 7-10am.\n",
            "Generated Code:\n",
            "var Hour = Meta.currentUserTime.hour()   if (Hour < 7 || Hour > 10) {   Slack.postToChannel.skip(\"Outside of commuting hours\") }\n",
            "Actual Code:\n",
            "var Hour = Meta.currentUserTime.hour()   if (Hour < 7 || Hour > 10) {   Slack.postToChannel.skip(\"Outside of commuting hours\") }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Hey Chicago: this Applet will send you a notification from the IFTTT app when there's an alert during your morning commute (7-9am on weekdays).\n",
            "Generated Code:\n",
            "var Day = Meta.currentUserTime.day() var Hour    Hour <7 || Hour > 9) {   IfNotifications.sendNotification.skip(\"Outside of commuting hours\") }   if (Day == 6 || Day == 7){   }  if (!Hour < 7 || (Hour > 9 && Hour < 7) || Hour < 19) { {  }\n",
            "Actual Code:\n",
            "var Day = Meta.currentUserTime.day() var Hour = Meta.currentUserTime.hour()  if (Day == 6 || Day ==7) {   IfNotifications.sendNotification.skip(\"Not a weekday\") }  if (Hour < 7 || Hour > 9) {   IfNotifications.sendNotification.skip(\"Not commuting hours\") }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Set a Yeelight Scene when sunset from Monday to Friday\n",
            "Generated Code:\n",
            "if (Meta.currentUserTime.locale('en').isoWeekday() >= 6) {   Yeelight.setScene.skip('Not Weekdays'); }\n",
            "Actual Code:\n",
            "if (Meta.currentUserTime.locale('en').isoWeekday() >= 6) {   Yeelight.setScene.skip('Not Weekdays'); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Closes the Main Gate every hour after 9 PM and until 7AM the next day.\n",
            "Generated Code:\n",
            "var hour = Meta.currentUserTime.hour()    if (hour < 7 && hour > 21) {   Gogogate.closeDoor.skip()  }\n",
            "Actual Code:\n",
            "var hour     = Meta.triggerTime.hour()     if (hour > 7 && hour < 21) {    Gogogate.closeDoor.skip()  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Dim Hue lights when motion detected on Arlo in the night\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();   if (timeOfDay > 7 && timeOfNight < 19) {   Hue.setBrightnessAllHue.skip() }\n",
            "Actual Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();  if (timeOfDay > 7 && timeOfDay < 19) {   Hue.setBrightnessAllHue.skip() }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Turn light on if time is after 7pm or before 7am\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour()  if (timeOfDay >= 7 && timeOfNight < 21) {   Lifx.turnOn.skip() }\n",
            "Actual Code:\n",
            "if ((Meta.currentUserTime.hour() <= 19) || (Meta.currentUserTime.hour() >= 7)) {     WemoLightSwitch.attributeLsOnDiscrete.skip(); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This Applet sends you an email when there's a service alert on Rapid Ride A line between the hours of 7-10am and 5-7pm.\n",
            "Generated Code:\n",
            "var Hour = Meta.currentUserTime.hour()   if (Hour <7 || (Hour > 10 && Hour < 17) || Hour > 19) {   Email.sendMeEmail.skip(\"Outside of commuting hours\") }\n",
            "Actual Code:\n",
            "var Hour = Meta.currentUserTime.hour()   if (Hour <7 || (Hour > 10 && Hour < 17) || Hour > 19) {   Email.sendMeEmail.skip(\"Outside of commuting hours\") }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Your lights will turn on when you're heading to a location, only if the time is after 8pm.\n",
            "Generated Code:\n",
            "var hour = Meta.currentUserTime.hour()  if (hour < 20) {   Lifx.turnOn.skip() }\n",
            "Actual Code:\n",
            "var hour = Meta.currentUserTime.hour()  if (hour < 20) {   Lifx.turnOn.skip() }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: We have your date night planned ahead of time, just tell us where and what day works for you! Impress your significant other every week with a new plan.\n",
            "Generated Code:\n",
            "let optionOne = Math.floor((Math.random() * Trakt.recommendedMovies.length)) let optionTwo = Yelp.searchBusiness.length(optionOne).toLowerCase() let optionThree = GoogleSheets.addDetailedSearch(optionTwo).setTitle(optionThree).setPhoto(optionFour).setLocation(optionFive)\n",
            "Actual Code:\n",
            "let optionOne = Math.floor((Math.random() * Trakt.recommendedMovies.length)) let optionTwo = Math.floor((Math.random() * Yelp.searchBusiness.length)) Email.sendMeEmail.setSubject(`It's night date night!`) Email.sendMeEmail.setBody(`Tonight you should watch ${Trakt.recommendedMovies[optionOne].MovieTitle}, and order dinner from ${Yelp.searchBusiness[optionTwo].BusinessName}! `)\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Which ever color tier your latest Super Chat message is, your Hue lights will change to match that color!\n",
            "Generated Code:\n",
            "if (Youtube.newSuperchat.ColorTier == \"Light blue\") {   Hue.setColorAllHue.setBrightness(\"#0092ff\") }\n",
            "Actual Code:\n",
            "if (Youtube.newSuperchat.ColorTier == \"Light blue\")   {Hue.setColorAllHue.setColor(\"#0092ff\")} if (Youtube.newSuperchat.ColorTier == \"Blue\")   {Hue.setColorAllHue.setColor(\"#4148b2\")}\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Example use case: You left work and going home on public transport and you need someone to pick you up from the station.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour()  if (timeOfDay >= 17 || timeOfHour < 5 ) {    AndroidMessages.sendAMessage.skip(\"Incorrect Hour: ${timeOfNote} and Day: ${dayOfWeek} combination\") }\n",
            "Actual Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour() var dayOfWeek = Meta.currentUserTime.isoWeekday()  if (!((timeOfDay >= 15 && timeOfDay <= 20 ) && (dayOfWeek >= 1 && dayOfWeek <= 5))) {      AndroidMessages.sendAMessage.skip(`Incorrect Hour: ${timeOfDay} and Day: ${dayOfWeek} combination`) }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet will turn your eWeLink 1 channel switch on or off when entering an area between 6pm and 6am. Example: Turn the front lights on when arriving home between 6pm and 6am.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();    if (timeOfDay > 18 || time ofDay < 6) {   Ewelink.switchAction.skip();  }\n",
            "Actual Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();    if (timeOfDay > 18 || timeOfDay < 6) {      } else {    Ewelink.switchAction.skip();  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This Applet sends you a heads-up notification when there's a DART rider alert during weekday commute hours (7-10am and 5-7pm).\n",
            "Generated Code:\n",
            "var Hour = Meta.currentUserTime.hour() var Day    Hour <7 || (Hour > 10 && Hour < 17) || Hour > 19) {   IfNotifications.sendNotification.skip(\"Outside of commuting hours\") }   if (Day == 6 || Day == 7){   Notifications.notifications.skip('Not a weekday') }\n",
            "Actual Code:\n",
            "var Hour = Meta.currentUserTime.hour() var Day = Meta.currentUserTime.day()   if (Hour <7 || (Hour > 10 && Hour < 17) || Hour > 19) {   IfNotifications.sendNotification.skip(\"Outside of commuting hours\") }   if (Day == 6 || Day == 7) {   IfNotifications.sendNotification.skip(\"Not a weekday\") }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Turns on lights when you arrive home, unless it's currently sunny.\n",
            "Generated Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentWeather.isBefore(sunset);  if (afterSunrise && beforeSunSet) {    Wyzecam.lightTurnOn.skip(`Its still daytime so we're leaving the lights off`);  }\n",
            "Actual Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt);  let sunset = moment(Weather.currentWeather[0].SunsetAt);  let currentTime = Meta.currentUserTime;  let afterSunrise = currentTime.isAfter(sunrise);  let beforeSunset = currentTime.isBefore(sunset);   if (afterSunrise && beforeSunset) {     Wyzecam.lightTurnOn.skip(`Its still daytime so we're leaving the lights off`);  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Feel safer when someone rings your doorbell at night. With this applet, your hue lights will automatically turn on if someone rings your Ring doorbell after 10pm.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();    if (timeOfDay > 22 || timeOfNight < 8 ) {   Hue.turnOnAllHue.skip()  }\n",
            "Actual Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour()    if (timeOfDay <= 22 || timeOfDay > 8 ) {       Hue.turnOnAllHue.skip()  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This Applet posts your pinned photos on Pinterest to Tumblr.\n",
            "Generated Code:\n",
            "Pinterest.aNewPinOnYourBoard.Description Tumblr.createPhotoPost\n",
            "Actual Code:\n",
            "Pinterest.aNewPinOnYourBoard.Description Tumblr.createPhotoPost\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet will reward you 1p for every 10 metres you cycle or run, from a pot of your choice, using Strava.\n",
            "Generated Code:\n",
            "var distance = parseInt(Strava.newActivityByYou.DistanceMeters); var amount = distance/1000; Monzo.potWithdraw.setAmount(amount.toFixed(2));\n",
            "Actual Code:\n",
            "var distance = parseInt(Strava.newActivityByYou.DistanceMeters); var amount = distance/1000; Monzo.potWithdraw.setAmount(amount.toFixed(2));\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: A detail report of your pet activity sent along to dropbox\n",
            "Generated Code:\n",
            "var hour = Meta.triggerTime.hour()  var timeHour = 24    if(hour%timeHour > 0 && minute%0 > 0 )   Dropbox.appendToTextFileDb.skip()\n",
            "Actual Code:\n",
            "var hour = Meta.triggerTime.hour()  var timeHour = 24  var minute = Meta.triggerTime.minute()    if(hour%timeHour > 0 && minute%10 > 0 )    Dropbox.appendToTextFileDb.skip()\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Your lights will turn on when you're heading to a location, only if the time is after 8pm.\n",
            "Generated Code:\n",
            "var hour = Meta.currentUserTime.hour()  if (hour < 20) {   Lifx.turnOn.skip() }\n",
            "Actual Code:\n",
            "var hour = Meta.currentUserTime.hour()  if (hour < 20) {   Lifx.turnOn.skip() }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: If doorbell rings beween 21h and 6h then toggle Hue lights on.\n",
            "Generated Code:\n",
            "var timeOfDay = Meta.currentUserTime.hour();   if (timeOfDay >= 21 || timeHour < 6) {   Hue.turnOnAllHue.skip() }\n",
            "Actual Code:\n",
            "var TimeOfDay = Meta.currentUserTime.hour()  if (TimeOfDay >= 21 || TimeOfDay < 6){   } else {  Hue.toggleAllHue.skip()  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Post notes you create in Notebook as tweets\n",
            "Generated Code:\n",
            "if (Twitter.newTweetByUser.Text.indexOf('Notebook') < 0) {    Twitter.postNewTweet.setTweet(\"Notebook created in Notebook\") }\n",
            "Actual Code:\n",
            "var htmlContent = Notebook.newTextNotecardInNotebook.NotecardHtmlContent; var text = htmlContent.replace(/<\\/?[^>]+>/gi, \" \"); Twitter.postNewTweet.setTweet(text);\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Enter your home address on the map and when you enter the radius your Hue lights will turn on, unless it's still light outside!\n",
            "Generated Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentWeather.isBefore(sunset);  if (afterSunrise && beforeSunSet) {    Hue.turnOnAllHue.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "Actual Code:\n",
            "let sunrise = moment(Weather.currentWeather[0].SunriseAt); let sunset = moment(Weather.currentWeather[0].SunsetAt); let currentTime = Meta.currentUserTime; let afterSunrise = currentTime.isAfter(sunrise); let beforeSunset = currentTime.isBefore(sunset);  if (afterSunrise && beforeSunset) {    Hue.turnOnAllHue.skip(`Its still daytime so we're leaving the lights off`); }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: When spending on Eating Out, take the amount from a Pot of your choosing\n",
            "Generated Code:\n",
            "if ( Monzo.cardPurchase.Category == \"Eating Out\" ) {    if (Monzo.potWithdraw.AmountInAccountCurrency.toUpperCase() > 0) { (\"Not an Eating Out Purchase\")   } else {  }\n",
            "Actual Code:\n",
            "if ( Monzo.cardPurchase.Category == \"Eating Out\" ) {    Monzo.potWithdraw.setAmount(Monzo.cardPurchase.AmountInAccountCurrency)  } else {    Monzo.potWithdraw.skip(\"Not an Eating Out Purchase\")  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: When paying for your Bus Fare or an Uber, take the amount from a Pot of your choosing. Works with anything that is categorised as \"Transport\" by Monzo.\n",
            "Generated Code:\n",
            "if ( Monzo.cardPurchase.Category == \"Transport\" ) {    if (Monzo.potWithdraw.AmountInAccountCurrency.toUpperCase() < 0) { (\"Not a Transport Purchase\")   } else {  }\n",
            "Actual Code:\n",
            "if ( Monzo.cardPurchase.Category == \"Transport\" ) {    Monzo.potWithdraw.setAmount(Monzo.cardPurchase.AmountInAccountCurrency)  } else {    Monzo.potWithdraw.skip(\"Not a Transport Purchase\")  }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: If the the moisture level measure by your Whisperer sensor is above 80%, skip all schedules for next few days.\n",
            "Generated Code:\n",
            "if(parseInt(Netro.sensorData.Moisture)<80){   Netro.noWater.skip() }\n",
            "Actual Code:\n",
            "if(parseInt(Netro.sensorData.Moisture)<80){   Netro.noWater.skip() }\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=128) and `max_length`(=128) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: This applet will append today's current Weather Underground report at the time you specify to a stream named \"weather-underground-today\" in a data.world dataset.\n",
            "Generated Code:\n",
            "const forecast = (Weather.currentWeatherAtTime as any) const pairs = Object.getOwnPropertyNames(forecast).map(prop => prop + \"||\" + forecast[prop]) Datadotworld.append.setPayload(pairs.join(\"|||\"))\n",
            "Actual Code:\n",
            "const forecast = (Weather.currentWeatherAtTime as any) const pairs = Object.getOwnPropertyNames(forecast).map(prop => prop + \"||\" + forecast[prop]) Datadotworld.append.setPayload(pairs.join(\"|||\"))\n",
            "--------------------------------------------------\n",
            "Prompt: This Applet sends you a notification from the IFTTT app when a new \"Ask Slashdot\" article is posted.\n",
            "Generated Code:\n",
            "var title = Trigger.EntryTitle var subject = 'Ask Slashdot'  if (title.indexOf(subject) < 0) {   IfNotifications.sendNotification.skip(\"Not an \"ask Slashdot\" article\") }\n",
            "Actual Code:\n",
            "var title = Trigger.EntryTitle var subject = 'Ask Slashdot'  if (title.indexOf(subject) < 0) {    IfNotifications.sendNotification.skip(\"Not an 'Ask Slashdot' article\") }\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: #zip nl2sql_bart/checkpoint-340\n",
        "\n",
        "!zip -r nl2sql_bart.zip nl2sql_bart/checkpoint-340\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ5wqGineBXP",
        "outputId": "a3a6ea36-833d-4a3c-9e56-f6b12d5f0fcc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: nl2sql_bart/checkpoint-340/ (stored 0%)\n",
            "  adding: nl2sql_bart/checkpoint-340/training_args.bin (deflated 52%)\n",
            "  adding: nl2sql_bart/checkpoint-340/config.json (deflated 63%)\n",
            "  adding: nl2sql_bart/checkpoint-340/tokenizer_config.json (deflated 76%)\n",
            "  adding: nl2sql_bart/checkpoint-340/generation_config.json (deflated 48%)\n",
            "  adding: nl2sql_bart/checkpoint-340/optimizer.pt (deflated 8%)\n",
            "  adding: nl2sql_bart/checkpoint-340/merges.txt (deflated 53%)\n",
            "  adding: nl2sql_bart/checkpoint-340/trainer_state.json (deflated 79%)\n",
            "  adding: nl2sql_bart/checkpoint-340/model.safetensors\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4866003,
          "sourceId": 8211052,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f984dc82a70349da8b1963c91ec038a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08470a47033b4872995121b0842c01ad",
              "IPY_MODEL_6283440b05ea45b789899d6b4bb4ff08",
              "IPY_MODEL_b8ce0f92adbf40a5bbe421b95b2abe1c"
            ],
            "layout": "IPY_MODEL_d8ea172060df4903b1eba13e0edc0430"
          }
        },
        "08470a47033b4872995121b0842c01ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57e89d5a7244322b699a61fd24d1bb5",
            "placeholder": "",
            "style": "IPY_MODEL_e5148926d6de429296c590daf1866f8d",
            "value": "Map:100%"
          }
        },
        "6283440b05ea45b789899d6b4bb4ff08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_042b923160e040bc8261197476c2b4aa",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50bb44e8ee7246b6925f162fd6539547",
            "value": 134
          }
        },
        "b8ce0f92adbf40a5bbe421b95b2abe1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b05f846c171243e68d3a889efc818220",
            "placeholder": "",
            "style": "IPY_MODEL_11911582efe548d1aa09460d920c91c2",
            "value": "134/134[00:00&lt;00:00,591.78examples/s]"
          }
        },
        "d8ea172060df4903b1eba13e0edc0430": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57e89d5a7244322b699a61fd24d1bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5148926d6de429296c590daf1866f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042b923160e040bc8261197476c2b4aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50bb44e8ee7246b6925f162fd6539547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b05f846c171243e68d3a889efc818220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11911582efe548d1aa09460d920c91c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d180341375cb49eeb61d28711ec05f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_614f3b3ef68b4bbb84c4a138fc5ebc71",
              "IPY_MODEL_6f5ee372130743aaaff8e8ca4a1052ea",
              "IPY_MODEL_fe481de94b1e4487a1bd6845f2709d1f"
            ],
            "layout": "IPY_MODEL_025e13a3fa2a4c7ea49111220ab1c7db"
          }
        },
        "614f3b3ef68b4bbb84c4a138fc5ebc71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146dc38546794240b5360a36c0a381a0",
            "placeholder": "",
            "style": "IPY_MODEL_a0c82245c1744d39a51a7ff844562ac6",
            "value": "Map:100%"
          }
        },
        "6f5ee372130743aaaff8e8ca4a1052ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb2c46f4600c4c03a54500bee2602fa1",
            "max": 34,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ed2c97d728e4204bfa22685e3d0c4be",
            "value": 34
          }
        },
        "fe481de94b1e4487a1bd6845f2709d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670c0d7167184fd4ad79441cb202747b",
            "placeholder": "",
            "style": "IPY_MODEL_0e2dde3f97b0460ead8f0b7205c3bf15",
            "value": "34/34[00:00&lt;00:00,510.86examples/s]"
          }
        },
        "025e13a3fa2a4c7ea49111220ab1c7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "146dc38546794240b5360a36c0a381a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c82245c1744d39a51a7ff844562ac6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb2c46f4600c4c03a54500bee2602fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ed2c97d728e4204bfa22685e3d0c4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "670c0d7167184fd4ad79441cb202747b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2dde3f97b0460ead8f0b7205c3bf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}