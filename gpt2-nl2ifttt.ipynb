{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b6fba7b87154e73a6628762ce62227b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dab66656e8740cba28622159e2caf88",
              "IPY_MODEL_05ddd0f3071e4f85a486f9baa5abbf0c",
              "IPY_MODEL_41c23d8d97ba4034afd80da5c7209daf"
            ],
            "layout": "IPY_MODEL_814ad5f6919b4626885742740874a55d"
          }
        },
        "2dab66656e8740cba28622159e2caf88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_717da7b80851492db880df0139a0a9b4",
            "placeholder": "​",
            "style": "IPY_MODEL_6662058a75f2438b9f11f53de29eaed1",
            "value": "Map: 100%"
          }
        },
        "05ddd0f3071e4f85a486f9baa5abbf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c98eb14bb884d1fbf3f945f4712c69c",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3153c676e034ea795addef23363682d",
            "value": 134
          }
        },
        "41c23d8d97ba4034afd80da5c7209daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bd4b3493a9c48df8c79302f2ea20ac0",
            "placeholder": "​",
            "style": "IPY_MODEL_c02d299276964880ae598bc2d93d5308",
            "value": " 134/134 [00:00&lt;00:00, 460.30 examples/s]"
          }
        },
        "814ad5f6919b4626885742740874a55d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "717da7b80851492db880df0139a0a9b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6662058a75f2438b9f11f53de29eaed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c98eb14bb884d1fbf3f945f4712c69c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3153c676e034ea795addef23363682d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3bd4b3493a9c48df8c79302f2ea20ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02d299276964880ae598bc2d93d5308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe9b88dd754b4a6cbf4051609c4cbe07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_960d71dd47904c8e8e72105966eeb25a",
              "IPY_MODEL_28dfb0cf8bfd401181a6aaf79e2fe9c6",
              "IPY_MODEL_7b1671ef11da465680ea214ef3764d38"
            ],
            "layout": "IPY_MODEL_20f511b590ac4a7d8a8acd249e72d73c"
          }
        },
        "960d71dd47904c8e8e72105966eeb25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fb57568bfc40289e53fc0e97e66ce3",
            "placeholder": "​",
            "style": "IPY_MODEL_62a7cd3b8ae246279255eff45fc986ff",
            "value": "Map: 100%"
          }
        },
        "28dfb0cf8bfd401181a6aaf79e2fe9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56553008b24342deb8ce13b337af0022",
            "max": 34,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_759d2c85822a4a8fa2307e5ae221a23a",
            "value": 34
          }
        },
        "7b1671ef11da465680ea214ef3764d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b94207542084404b98424dffc7d5c6d",
            "placeholder": "​",
            "style": "IPY_MODEL_c83577f40d6344be8544e121b841384b",
            "value": " 34/34 [00:00&lt;00:00, 186.51 examples/s]"
          }
        },
        "20f511b590ac4a7d8a8acd249e72d73c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fb57568bfc40289e53fc0e97e66ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a7cd3b8ae246279255eff45fc986ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56553008b24342deb8ce13b337af0022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759d2c85822a4a8fa2307e5ae221a23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b94207542084404b98424dffc7d5c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83577f40d6344be8544e121b841384b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benedettoscala/ifttt-code-generator/blob/main/gpt2-nl2ifttt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup and Library Imports\n",
        "This section installs the necessary libraries, imports key dependencies, and sets up the workspace.\n",
        "\n",
        "#### **Dependency Installation**\n",
        "- The following libraries are installed:\n",
        "  - `transformers`: Provides pre-trained language models and utilities for NLP tasks.\n",
        "  - `evaluate`: Enables performance evaluation of language models.\n",
        "  - `datasets`: Facilitates dataset handling for training and testing.\n",
        "  - `rouge_score`: (Optional) Used for text-based evaluation metrics, though not strictly needed for GPT-2.\n",
        "\n",
        "#### **Library Imports**\n",
        "- **General Libraries:**\n",
        "  - `os`, `pandas`, `numpy`, and `math` for file handling, data manipulation, and numerical operations.\n",
        "  - `torch` for deep learning computations.\n",
        "- **Machine Learning and NLP Libraries:**\n",
        "  - `sklearn.model_selection` for dataset splitting (train-test split).\n",
        "  - `datasets.Dataset, DatasetDict` for dataset management.\n",
        "  - `transformers`:\n",
        "    - `GPT2LMHeadModel`: Pre-trained GPT-2 model for causal language modeling.\n",
        "    - `GPT2Tokenizer`: Tokenizer for text processing with GPT-2.\n",
        "    - `DataCollatorForLanguageModeling`: Ensures proper batching and padding of sequences.\n",
        "    - `Trainer`: Simplifies training and evaluation of transformers models.\n",
        "    - `TrainingArguments`: Defines hyperparameters for training.\n",
        "- **Evaluation Libraries:**\n",
        "  - `evaluate` for model performance measurement.\n",
        "  - `nltk` for natural language processing utilities, including tokenization.\n",
        "\n",
        "#### **NLTK Resource Download**\n",
        "- If the `punkt` tokenizer is missing, it is downloaded to ensure correct text tokenization.\n",
        "\n",
        "#### **Repository Cloning**\n",
        "- The script clones the `ifttt-code-generator` repository from GitHub.\n",
        "- It navigates to the repository directory and updates it with `git pull`.\n",
        "\n",
        "This setup ensures a well-prepared environment for training and evaluating language models.\n"
      ],
      "metadata": {
        "id": "dT0gzOyqz-0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfeAmfUtewJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec962cb4-1a47-45d9-8060-6856f2f03dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers evaluate datasets\n",
        "!pip install rouge_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "import evaluate\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "nltk.download(\"punkt\")\n"
      ],
      "metadata": {
        "id": "OK53MGuYezMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "243e5ae1-472c-4aaf-eff7-1ddd4b9d7335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benedettoscala/ifttt-code-generator\n",
        "%cd ifttt-code-generator/\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7hBCYyJe34G",
        "outputId": "25841d53-f3fe-42d2-ea19-9bf89626d01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ifttt-code-generator' already exists and is not an empty directory.\n",
            "/content/ifttt-code-generator\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading and Preprocessing\n",
        "This section loads, cleans, and prepares the dataset for training a language model.\n",
        "\n",
        "#### **Dataset Loading and Cleaning**\n",
        "- The dataset is loaded from a CSV file (`cleaned_and_combined.csv`).\n",
        "- Rows containing missing values in `cleaned_description` or `filter_code` columns are removed.\n",
        "- Duplicate entries in these columns are also dropped to ensure unique data points.\n",
        "\n",
        "#### **Text Formatting for Model Input**\n",
        "- A **prompt template** is created to format each example:\n",
        "  - The **description** and **code** are combined into a single string using a separator (`###`).\n",
        "  - This structure helps the model distinguish between input text (description) and the expected output (code).\n",
        "  - Example format:\n",
        "    ```\n",
        "    Description:\n",
        "    <description_text>\n",
        "    ###\n",
        "    Code:\n",
        "    <code_text>\n",
        "    ```\n",
        "- The `create_text_prompt` function applies this formatting to all dataset entries.\n",
        "\n",
        "#### **Train/Test Split**\n",
        "- The dataset is split into:\n",
        "  - **80% Training Data**\n",
        "  - **20% Testing Data**\n",
        "- The split is **random but reproducible** (`random_state=42` ensures consistency across runs).\n",
        "\n",
        "#### **Conversion to Hugging Face Dataset Format**\n",
        "- The train and test dataframes are converted into `Dataset` objects for seamless compatibility with the Hugging Face training pipeline.\n",
        "- A `DatasetDict` structure is created to organize training and testing subsets.\n",
        "\n",
        "#### **Dataset Size Display**\n",
        "- The script prints the number of examples in both the training and test sets.\n",
        "\n",
        "This structured dataset preparation ensures the model receives properly formatted inputs and enables efficient training.\n"
      ],
      "metadata": {
        "id": "4z76hQwz0T11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carica il dataset\n",
        "csv_path = \"datasets/cleaned_and_combined.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Rimuovi righe con valori mancanti e duplicati\n",
        "df.dropna(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "df.drop_duplicates(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "\n",
        "def create_text_prompt(desc, code):\n",
        "    return f\"Description:\\n{desc}\\n###\\nCode:\\n{code}\"\n",
        "\n",
        "df[\"text\"] = df.apply(\n",
        "    lambda row: create_text_prompt(row[\"cleaned_description\"], row[\"filter_code\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Divisione train/test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Conversione in Dataset Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "\n",
        "print(\"Train set size:\", len(dataset[\"train\"]))\n",
        "print(\"Test set size:\", len(dataset[\"test\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIorN96Pe116",
        "outputId": "4a659da8-9284-4ec0-8b41-a5e875dd2278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 134\n",
            "Test set size: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer Setup and Dataset Tokenization\n",
        "This section prepares the tokenizer and tokenizes the dataset for training with GPT-2.\n",
        "\n",
        "#### **Tokenizer Configuration**\n",
        "- The tokenizer is loaded from the pre-trained `GPT-2` model\n",
        "  - GPT-2 does not have a default padding token, so the EOS (`end-of-sequence`) token is assigned as the padding token.\n",
        "\n",
        "#### **Tokenization Function**\n",
        "- **Input Processing:**\n",
        "  - Each text sample is tokenized using the GPT-2 tokenizer.\n",
        "  - `padding=\"max_length\"` ensures all sequences have a fixed size (`256` tokens) for efficient batch processing.\n",
        "  - `truncation=True` prevents sequences from exceeding the maximum length.\n",
        "  - **Note:** the longest entry in the dataset is 200 token long.\n",
        "\n",
        "#### **Tokenizing the Dataset**\n",
        "- The dataset is processed using `.map()` to apply tokenization to all examples in batches.\n",
        "- The `remove_columns` parameter ensures only the necessary tokenized fields (`input_ids`, `attention_mask`) remain.\n",
        "\n",
        "#### **Final Output**\n",
        "- The `tokenized_datasets` object contains the processed dataset, ready for model training.\n",
        "\n",
        "This setup ensures the dataset is efficiently formatted for fine-tuning GPT-2.\n"
      ],
      "metadata": {
        "id": "7qLaNi6l0jZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint)\n",
        "# Imposta un token di padding se non definito\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
        "\n",
        "# Imposta una lunghezza massima\n",
        "max_length = 256\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Ritorna un unico dict con input_ids e attention_mask\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n",
        "\n",
        "tokenized_datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "9b6fba7b87154e73a6628762ce62227b",
            "2dab66656e8740cba28622159e2caf88",
            "05ddd0f3071e4f85a486f9baa5abbf0c",
            "41c23d8d97ba4034afd80da5c7209daf",
            "814ad5f6919b4626885742740874a55d",
            "717da7b80851492db880df0139a0a9b4",
            "6662058a75f2438b9f11f53de29eaed1",
            "5c98eb14bb884d1fbf3f945f4712c69c",
            "b3153c676e034ea795addef23363682d",
            "3bd4b3493a9c48df8c79302f2ea20ac0",
            "c02d299276964880ae598bc2d93d5308",
            "fe9b88dd754b4a6cbf4051609c4cbe07",
            "960d71dd47904c8e8e72105966eeb25a",
            "28dfb0cf8bfd401181a6aaf79e2fe9c6",
            "7b1671ef11da465680ea214ef3764d38",
            "20f511b590ac4a7d8a8acd249e72d73c",
            "e9fb57568bfc40289e53fc0e97e66ce3",
            "62a7cd3b8ae246279255eff45fc986ff",
            "56553008b24342deb8ce13b337af0022",
            "759d2c85822a4a8fa2307e5ae221a23a",
            "8b94207542084404b98424dffc7d5c6d",
            "c83577f40d6344be8544e121b841384b"
          ]
        },
        "id": "xWYQtcfse9ZK",
        "outputId": "9b012aba-e981-4e80-ed06-44b14561ce57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/134 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b6fba7b87154e73a6628762ce62227b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe9b88dd754b4a6cbf4051609c4cbe07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 134\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 34\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Causal Language Modeling\n",
        ")\n"
      ],
      "metadata": {
        "id": "yHGDzgnNfC1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Aggiungiamo eventuali token se abbiamo aggiunto un token di pad\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50xLv--IfEkJ",
        "outputId": "9bd4c8c2-271b-416a-fc11-0edb9f3f5d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics and Text Postprocessing\n",
        "This section defines the evaluation metrics and a helper function to preprocess text for evaluation.\n",
        "\n",
        "#### **Evaluation Metrics**\n",
        "- **ROUGE:** Measures overlap between n-grams, sequences, and longest common subsequences between predictions and references. Ideal for summarization and text generation tasks.\n",
        "- **BLEU:** Evaluates the precision of generated words compared to reference texts, often used for translation tasks.\n",
        "- **METEOR:** Focuses on synonym matching, stemming, and word order, providing a nuanced evaluation for generated text.\n",
        "\n",
        "The metrics are loaded using the `evaluate` library, enabling easy integration into the training and evaluation workflow.\n",
        "\n",
        "#### **Postprocessing Function**\n",
        "- The `postprocess_text` function ensures predictions and references are properly formatted for accurate metric computation:\n",
        "  - **Whitespace Cleanup:** Removes unnecessary spaces from both predictions and labels.\n",
        "  - **Sentence Tokenization:** Segments predictions and references into sentences using NLTK's `sent_tokenize` to align with how ROUGE calculates scores.\n",
        "\n",
        "This preprocessing ensures consistency and improves the reliability of the evaluation metrics.\n"
      ],
      "metadata": {
        "id": "tz4rWFZ91Kqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score = evaluate.load(\"rouge\")\n",
        "bleu_score  = evaluate.load(\"bleu\")\n",
        "meteor_score = evaluate.load(\"meteor\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    \"\"\"\n",
        "    - Rimuove spazi superflui\n",
        "    - Segmenta in frasi per calcolare ROUGE in modo corretto\n",
        "    \"\"\"\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "    return preds, labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWd2IpvqpW2U",
        "outputId": "ba652c78-36ec-4f86-e894-b5aabed7e019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Metrics Function for Model Evaluation\n",
        "This function computes **ROUGE**, **BLEU**, and **METEOR** scores to evaluate model-generated text against reference labels.\n",
        "\n",
        "#### **Processing Predictions and Labels**\n",
        "- The function receives model `logits` (raw outputs) and `labels` (ground truth).\n",
        "- **Handling Masked Tokens:**  \n",
        "  - In **GPT-2**, `-100` is not typically used for ignored tokens (as in seq2seq models).\n",
        "  - If present, it is replaced with the tokenizer’s pad token.\n",
        "- **Argmax Decoding:**  \n",
        "  - The highest probability token is selected for each position in the logits.\n",
        "  - The resulting token IDs are converted into human-readable text using `batch_decode()`.\n",
        "\n",
        "#### **Post-Processing**\n",
        "- **Whitespace Cleanup & Sentence Splitting:**  \n",
        "  - Predictions and labels are preprocessed using `postprocess_text()`.\n",
        "  - This ensures proper tokenization for ROUGE and improves metric accuracy.\n",
        "\n",
        "#### **Metric Computation**\n",
        "- **ROUGE:**  \n",
        "  - Measures n-gram overlap between predictions and references.\n",
        "- **BLEU:**  \n",
        "  - `evaluate` requires references in a **list of lists** format (`[[reference]]`).\n",
        "  - Measures word sequence precision against references.\n",
        "- **METEOR:**  \n",
        "  - Considers synonym matching, stemming, and word order for better evaluation.\n",
        "\n",
        "#### **Result Formatting**\n",
        "- Scores are converted to percentages (`*100`) and rounded for readability.\n",
        "- The final dictionary contains:\n",
        "  - **ROUGE-1, ROUGE-2, ROUGE-L** (n-gram and longest common subsequence similarity)\n",
        "  - **BLEU** (precision-based similarity)\n",
        "  - **METEOR** (semantic matching)\n",
        "\n",
        "This function ensures a **comprehensive evaluation** of model-generated text.\n"
      ],
      "metadata": {
        "id": "zv1Wqbgy18te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    #se si usa -100 come padding token lo sostituiamoc con quello usato da gpt-2\n",
        "    labels[labels == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # Argmax sui logits per ottenere la sequenza predetta\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Decodifica in stringhe\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Post-processing (rimozione spazi, split in frasi)\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Calcolo delle metriche\n",
        "    # 1) ROUGE\n",
        "    rouge_results = rouge_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels\n",
        "    )\n",
        "    # 2) BLEU\n",
        "    # La metrica BLEU in `evaluate` richiede `references` come lista di liste\n",
        "    bleu_results = bleu_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=[[lbl] for lbl in decoded_labels]\n",
        "    )\n",
        "    # 3) METEOR\n",
        "    meteor_results = meteor_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels\n",
        "    )\n",
        "\n",
        "    # Organizza i risultati\n",
        "    result = {}\n",
        "    # ROUGE\n",
        "    result[\"rouge1\"] = round(rouge_results[\"rouge1\"] * 100, 2)\n",
        "    result[\"rouge2\"] = round(rouge_results[\"rouge2\"] * 100, 2)\n",
        "    result[\"rougeL\"] = round(rouge_results[\"rougeL\"] * 100, 2)\n",
        "    # BLEU\n",
        "    result[\"bleu\"] = round(bleu_results[\"bleu\"] * 100, 2)\n",
        "    # METEOR\n",
        "    result[\"meteor\"] = round(meteor_results[\"meteor\"] * 100, 2)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "nzD11TV3fGVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ARvJpBGkf41b",
        "outputId": "f83daa82-5e81-43e8-9437-7e4870335355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Configuration and Trainer Initialization\n",
        "This section configures the training arguments and initializes the `Trainer` for fine-tuning GPT-2 on IFTTT-like tasks.\n",
        "\n",
        "#### **Training Arguments Configuration**\n",
        "- **Output Directory:**  \n",
        "  - Saves model checkpoints in `./gpt2-ifttt`.\n",
        "  - Overwrites existing checkpoints if `overwrite_output_dir=True`.\n",
        "- **Evaluation & Checkpointing Strategy:**  \n",
        "  - `evaluation_strategy=\"epoch\"` → Evaluates the model at the end of each epoch.\n",
        "  - `save_strategy=\"epoch\"` → Saves model checkpoints at the end of each epoch.\n",
        "- **Training Hyperparameters:**  \n",
        "  - `num_train_epochs=30` → Trains for 30 epochs (adjust based on dataset size and performance).\n",
        "  - `per_device_train_batch_size=4` → Processes 4 examples per batch (adjust based on GPU memory).\n",
        "  - `per_device_eval_batch_size=4` → Uses the same batch size for evaluation.\n",
        "- **Logging & Precision:**  \n",
        "  - `logging_steps=50` → Logs progress every 50 steps.\n",
        "  - `fp16=torch.cuda.is_available()` → Uses **mixed precision** (`fp16`) if a compatible GPU is available, improving efficiency.\n",
        "  - `report_to=\"none\"` → Disables logging to external tools like WandB.\n",
        "\n",
        "#### **Trainer Initialization**\n",
        "- The `Trainer` class simplifies training by handling:\n",
        "  - **Model Training & Evaluation:** Uses the specified datasets.\n",
        "  - **Data Collation:** Ensures correct batch formatting using `data_collator`.\n",
        "  - **Tokenization:** Ensures consistency in input processing.\n",
        "  - **Metric Computation:** If `compute_metrics` is provided, the model's performance is evaluated after each epoch.\n",
        "\n",
        "This setup allows for an **automated and structured training process**, including evaluation and checkpointing.\n"
      ],
      "metadata": {
        "id": "lqRz8jua2Rwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/Shareddrives/NLPMODELS/gpt2model\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",   # Esegui evaluation alla fine di ogni epoca\n",
        "    #save_strategy=\"epoch\",         # Salva un checkpoint a ogni epoca\n",
        "    num_train_epochs=20,            # Cambia secondo le tue necessità\n",
        "    per_device_train_batch_size=8, # Batch size, adattalo alla tua GPU\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(), # Usa half precision se possibile\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XH_lOb5fH5l",
        "outputId": "76dba64e-aa1f-45a5-b09d-9b96961d5ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-11-b0d9e6469ca2>:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "42zsMe1ofJDf",
        "outputId": "707d269b-392d-4af7-d83e-ed221f86cd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [340/340 02:33, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Meteor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.535383</td>\n",
              "      <td>42.580000</td>\n",
              "      <td>14.890000</td>\n",
              "      <td>34.390000</td>\n",
              "      <td>24.750000</td>\n",
              "      <td>43.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.156899</td>\n",
              "      <td>46.210000</td>\n",
              "      <td>19.420000</td>\n",
              "      <td>40.190000</td>\n",
              "      <td>22.820000</td>\n",
              "      <td>48.610000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.580500</td>\n",
              "      <td>2.010765</td>\n",
              "      <td>47.740000</td>\n",
              "      <td>20.580000</td>\n",
              "      <td>42.490000</td>\n",
              "      <td>32.370000</td>\n",
              "      <td>51.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.580500</td>\n",
              "      <td>1.913291</td>\n",
              "      <td>50.350000</td>\n",
              "      <td>24.050000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>33.900000</td>\n",
              "      <td>54.720000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.580500</td>\n",
              "      <td>1.878177</td>\n",
              "      <td>50.040000</td>\n",
              "      <td>24.380000</td>\n",
              "      <td>44.900000</td>\n",
              "      <td>35.890000</td>\n",
              "      <td>55.510000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.584100</td>\n",
              "      <td>1.827517</td>\n",
              "      <td>50.610000</td>\n",
              "      <td>25.760000</td>\n",
              "      <td>45.780000</td>\n",
              "      <td>37.510000</td>\n",
              "      <td>56.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.584100</td>\n",
              "      <td>1.810050</td>\n",
              "      <td>52.210000</td>\n",
              "      <td>27.590000</td>\n",
              "      <td>47.600000</td>\n",
              "      <td>39.590000</td>\n",
              "      <td>58.360000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.584100</td>\n",
              "      <td>1.795711</td>\n",
              "      <td>53.060000</td>\n",
              "      <td>28.570000</td>\n",
              "      <td>48.410000</td>\n",
              "      <td>41.410000</td>\n",
              "      <td>58.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.241300</td>\n",
              "      <td>1.778932</td>\n",
              "      <td>53.400000</td>\n",
              "      <td>29.530000</td>\n",
              "      <td>49.020000</td>\n",
              "      <td>40.960000</td>\n",
              "      <td>59.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.241300</td>\n",
              "      <td>1.765897</td>\n",
              "      <td>55.130000</td>\n",
              "      <td>32.170000</td>\n",
              "      <td>50.850000</td>\n",
              "      <td>43.630000</td>\n",
              "      <td>60.230000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.241300</td>\n",
              "      <td>1.782622</td>\n",
              "      <td>54.400000</td>\n",
              "      <td>32.110000</td>\n",
              "      <td>50.570000</td>\n",
              "      <td>44.040000</td>\n",
              "      <td>59.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.012000</td>\n",
              "      <td>1.773015</td>\n",
              "      <td>55.610000</td>\n",
              "      <td>33.570000</td>\n",
              "      <td>51.920000</td>\n",
              "      <td>45.650000</td>\n",
              "      <td>60.820000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.012000</td>\n",
              "      <td>1.793912</td>\n",
              "      <td>54.540000</td>\n",
              "      <td>32.330000</td>\n",
              "      <td>50.950000</td>\n",
              "      <td>44.530000</td>\n",
              "      <td>60.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.012000</td>\n",
              "      <td>1.798213</td>\n",
              "      <td>54.560000</td>\n",
              "      <td>32.400000</td>\n",
              "      <td>50.670000</td>\n",
              "      <td>45.140000</td>\n",
              "      <td>61.070000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.855200</td>\n",
              "      <td>1.803816</td>\n",
              "      <td>54.650000</td>\n",
              "      <td>32.580000</td>\n",
              "      <td>51.040000</td>\n",
              "      <td>46.140000</td>\n",
              "      <td>61.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.855200</td>\n",
              "      <td>1.823668</td>\n",
              "      <td>54.630000</td>\n",
              "      <td>32.450000</td>\n",
              "      <td>51.190000</td>\n",
              "      <td>45.720000</td>\n",
              "      <td>60.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.855200</td>\n",
              "      <td>1.829415</td>\n",
              "      <td>54.620000</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>51.020000</td>\n",
              "      <td>45.940000</td>\n",
              "      <td>61.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.754900</td>\n",
              "      <td>1.827648</td>\n",
              "      <td>54.850000</td>\n",
              "      <td>32.740000</td>\n",
              "      <td>51.280000</td>\n",
              "      <td>46.200000</td>\n",
              "      <td>61.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.754900</td>\n",
              "      <td>1.834705</td>\n",
              "      <td>54.740000</td>\n",
              "      <td>32.650000</td>\n",
              "      <td>51.330000</td>\n",
              "      <td>45.980000</td>\n",
              "      <td>61.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.754900</td>\n",
              "      <td>1.837422</td>\n",
              "      <td>54.780000</td>\n",
              "      <td>32.660000</td>\n",
              "      <td>51.270000</td>\n",
              "      <td>45.860000</td>\n",
              "      <td>61.130000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=340, training_loss=1.2648966620950137, metrics={'train_runtime': 154.5639, 'train_samples_per_second': 17.339, 'train_steps_per_second': 2.2, 'total_flos': 350131322880000.0, 'train_loss': 1.2648966620950137, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(\"Final eval_loss:\", results[\"eval_loss\"])\n",
        "print(\"Perplexity:\", math.exp(results[\"eval_loss\"]))\n"
      ],
      "metadata": {
        "id": "INTOEO_YfKA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "504f3fce-57a3-41c3-d9aa-335b1415a950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final eval_loss: 1.8374218940734863\n",
            "Perplexity: 6.280326025828933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ_N_fG9shO0",
        "outputId": "a10d453c-2abf-4dee-ee5b-7c9ab5470bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your shared folder in Google Drive\n",
        "shared_folder_path = \"/content/drive/Shareddrives/NLPMODELS/\"\n",
        "\n",
        "# Create the shared folder if it doesn't exist\n",
        "!mkdir -p \"{shared_folder_path}\"\n",
        "\n",
        "# Save the nl2sql_bart folder to your shared Google Drive folder\n",
        "!cp -r gpt2-ifttt \"{shared_folder_path}\""
      ],
      "metadata": {
        "id": "UVKyJ6sC5xxF",
        "outputId": "f7df4a56-8e32-4dcb-82b8-9bbf36f0983e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cp: cannot stat 'gpt2-ifttt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_path = \"/content/drive/Shareddrives/NLPMODELS/gpt2model/checkpoint-340\"\n",
        "\n",
        "inference_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "inference_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Pipeline di text generation\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=inference_model,\n",
        "    tokenizer=inference_tokenizer,\n",
        "    pad_token_id=inference_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Esempio di prompt: solo la \"descrizione\"\n",
        "prompt = \"Description:\\nCreate an applet that Save new photos from my phone to a Google Drive folder automatically.\\n###\\nCode:\\n\"\n",
        "\n",
        "results = generator(prompt, max_length=256, num_return_sequences=1)\n",
        "print(results[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "id": "5PdTIGNIfLLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfa2c1c-becb-404e-ab0f-04e9ed60c22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description:\n",
            "Create an applet that Save new photos from my phone to a Google Drive folder automatically.\n",
            "###\n",
            "Code:\n",
            "var photo = Object.getOwnPropertyNames(CameraPhoto.locale').toLowerCase()  var w = Meta.currentUserTime.format('dddd').toLowerCase()   if (w.locale === 'US') {   FolderFolder.createFolder.skip(\"Uploaded Photos\") } else {  GooglePhoto.uploadPhotoFolder.skip(\"Not Google Photos Folder\") }  } else{   Folder.createFolder.skip(\"Search for Photos\") }   }  if (photo.length!= 0 && photo.length!= 1) {  Folder.createFolder.skip(\"Not Dropbox\") }  else{  Folder.createFolder.skip(\"Not Photos\") }  }    if (w.locale === 'US') {   Folder.createFolder.skip(\"Not Android\") }  else{  Folder.createFolder.skip(\"Android Save Folder\") }  }  }   if (w.locale === 'Canada') {   Folder.createFolder.skip(\"Not AUS Folder\") }  else{\n"
          ]
        }
      ]
    }
  ]
}