{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27e72ab4e56b4ab29f27560ae6621040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76e8cad32f8445a7a88b7d5873769b2b",
              "IPY_MODEL_f2e80c702c514b3d836eaa296dcf10bd",
              "IPY_MODEL_5a9c61ed4a674ade9e11b16e4171e8de"
            ],
            "layout": "IPY_MODEL_4ffd946925034d5684ffca188ad61e9c"
          }
        },
        "76e8cad32f8445a7a88b7d5873769b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccda8dc9b61a4276bd857c943b2e4260",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbaec8a76a849668568db1a987fcab6",
            "value": "Map: 100%"
          }
        },
        "f2e80c702c514b3d836eaa296dcf10bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb6b9e9be6b64c8e8ed723d18e32dc75",
            "max": 134,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1d21ff0c5934b51a078795cb0ec4f0f",
            "value": 134
          }
        },
        "5a9c61ed4a674ade9e11b16e4171e8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc54bc9dda44946a6798fd8d301d29e",
            "placeholder": "​",
            "style": "IPY_MODEL_6b7b46b4b6604d068524206b4991d3d9",
            "value": " 134/134 [00:00&lt;00:00, 788.57 examples/s]"
          }
        },
        "4ffd946925034d5684ffca188ad61e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccda8dc9b61a4276bd857c943b2e4260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbaec8a76a849668568db1a987fcab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb6b9e9be6b64c8e8ed723d18e32dc75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d21ff0c5934b51a078795cb0ec4f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "edc54bc9dda44946a6798fd8d301d29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7b46b4b6604d068524206b4991d3d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361027af7e6f4150b169e76a3582c456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55cbb046b06a42d388c9fabbe99a5b26",
              "IPY_MODEL_cf722fe5d7874faaac527179e21db0f4",
              "IPY_MODEL_9bf9a77ccd084922b10d55c56f4442c8"
            ],
            "layout": "IPY_MODEL_336f2b09ae22490aaba2fa9b9f8c8997"
          }
        },
        "55cbb046b06a42d388c9fabbe99a5b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5165709bbcf043f0abc419884cdad32c",
            "placeholder": "​",
            "style": "IPY_MODEL_c7130e462740451b828b470419a58b7d",
            "value": "Map: 100%"
          }
        },
        "cf722fe5d7874faaac527179e21db0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c189c45af84cb693bb1fc3e00e1230",
            "max": 34,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4de0272de7a487383ea4f9924446b72",
            "value": 34
          }
        },
        "9bf9a77ccd084922b10d55c56f4442c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3c6db1cb63c464a9a6e038cf67dfee8",
            "placeholder": "​",
            "style": "IPY_MODEL_18537cf95d7f4080a5c3d2ef2d295c31",
            "value": " 34/34 [00:00&lt;00:00, 401.05 examples/s]"
          }
        },
        "336f2b09ae22490aaba2fa9b9f8c8997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5165709bbcf043f0abc419884cdad32c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7130e462740451b828b470419a58b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48c189c45af84cb693bb1fc3e00e1230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4de0272de7a487383ea4f9924446b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3c6db1cb63c464a9a6e038cf67dfee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18537cf95d7f4080a5c3d2ef2d295c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benedettoscala/ifttt-code-generator/blob/main/gpt2-nl2ifttt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Environment Setup and Library Imports\n",
        "This section installs the necessary libraries, imports key dependencies, and sets up the workspace.\n",
        "\n",
        "#### **Dependency Installation**\n",
        "- The following libraries are installed:\n",
        "  - `transformers`: Provides pre-trained language models and utilities for NLP tasks.\n",
        "  - `evaluate`: Enables performance evaluation of language models.\n",
        "  - `datasets`: Facilitates dataset handling for training and testing.\n",
        "  - `rouge_score`: (Optional) Used for text-based evaluation metrics, though not strictly needed for GPT-2.\n",
        "\n",
        "#### **Library Imports**\n",
        "- **General Libraries:**\n",
        "  - `os`, `pandas`, `numpy`, and `math` for file handling, data manipulation, and numerical operations.\n",
        "  - `torch` for deep learning computations.\n",
        "- **Machine Learning and NLP Libraries:**\n",
        "  - `sklearn.model_selection` for dataset splitting (train-test split).\n",
        "  - `datasets.Dataset, DatasetDict` for dataset management.\n",
        "  - `transformers`:\n",
        "    - `GPT2LMHeadModel`: Pre-trained GPT-2 model for causal language modeling.\n",
        "    - `GPT2Tokenizer`: Tokenizer for text processing with GPT-2.\n",
        "    - `DataCollatorForLanguageModeling`: Ensures proper batching and padding of sequences.\n",
        "    - `Trainer`: Simplifies training and evaluation of transformers models.\n",
        "    - `TrainingArguments`: Defines hyperparameters for training.\n",
        "- **Evaluation Libraries:**\n",
        "  - `evaluate` for model performance measurement.\n",
        "  - `nltk` for natural language processing utilities, including tokenization.\n",
        "\n",
        "#### **NLTK Resource Download**\n",
        "- If the `punkt` tokenizer is missing, it is downloaded to ensure correct text tokenization.\n",
        "\n",
        "#### **Repository Cloning**\n",
        "- The script clones the `ifttt-code-generator` repository from GitHub.\n",
        "- It navigates to the repository directory and updates it with `git pull`.\n",
        "\n",
        "This setup ensures a well-prepared environment for training and evaluating language models.\n"
      ],
      "metadata": {
        "id": "dT0gzOyqz-0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NfeAmfUtewJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e614738-cb6c-4a9b-8e6d-638ba6c84a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=fb5bd8fcd78988906d6e33d590ebbd136ec35cfc63e3c94c073b8639e5c9115f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers evaluate datasets\n",
        "!pip install rouge_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import (\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2Tokenizer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "import evaluate\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "nltk.download(\"punkt\")\n"
      ],
      "metadata": {
        "id": "OK53MGuYezMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2f94fef-5085-4ca5-8f54-19fa8104ab11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/benedettoscala/ifttt-code-generator\n",
        "%cd ifttt-code-generator/\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7hBCYyJe34G",
        "outputId": "34be8634-5287-41ef-aa51-66b12e17af65"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ifttt-code-generator'...\n",
            "remote: Enumerating objects: 236, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 236 (delta 47), reused 0 (delta 0), pack-reused 157 (from 1)\u001b[K\n",
            "Receiving objects: 100% (236/236), 14.97 MiB | 20.88 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n",
            "/ifttt-code-generator\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading and Preprocessing\n",
        "This section loads, cleans, and prepares the dataset for training a language model.\n",
        "\n",
        "#### **Dataset Loading and Cleaning**\n",
        "- The dataset is loaded from a CSV file (`cleaned_and_combined.csv`).\n",
        "- Rows containing missing values in `cleaned_description` or `filter_code` columns are removed.\n",
        "- Duplicate entries in these columns are also dropped to ensure unique data points.\n",
        "\n",
        "#### **Text Formatting for Model Input**\n",
        "- A **prompt template** is created to format each example:\n",
        "  - The **description** and **code** are combined into a single string using a separator (`###`).\n",
        "  - This structure helps the model distinguish between input text (description) and the expected output (code).\n",
        "  - Example format:\n",
        "    ```\n",
        "    <description_text>\n",
        "    ###\n",
        "    <code_text>\n",
        "    ```\n",
        "- The `create_text_prompt` function applies this formatting to all dataset entries.\n",
        "\n",
        "#### **Train/Test Split**\n",
        "- The dataset is split into:\n",
        "  - **80% Training Data**\n",
        "  - **20% Testing Data**\n",
        "- The split is **random but reproducible** (`random_state=42` ensures consistency across runs).\n",
        "\n",
        "#### **Conversion to Hugging Face Dataset Format**\n",
        "- The train and test dataframes are converted into `Dataset` objects for seamless compatibility with the Hugging Face training pipeline.\n",
        "- A `DatasetDict` structure is created to organize training and testing subsets.\n",
        "\n",
        "#### **Dataset Size Display**\n",
        "- The script prints the number of examples in both the training and test sets.\n",
        "\n",
        "This structured dataset preparation ensures the model receives properly formatted inputs and enables efficient training.\n"
      ],
      "metadata": {
        "id": "4z76hQwz0T11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carica il dataset\n",
        "csv_path = \"datasets/cleaned_and_combined.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Rimuovi righe con valori mancanti e duplicati\n",
        "df.dropna(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "df.drop_duplicates(subset=[\"cleaned_description\", \"filter_code\"], inplace=True)\n",
        "\n",
        "def create_text_prompt(desc, code):\n",
        "    return f\"{desc}\\n###\\n{code}\"\n",
        "\n",
        "df[\"text\"] = df.apply(\n",
        "    lambda row: create_text_prompt(row[\"cleaned_description\"], row[\"filter_code\"]),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Divisione train/test\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Conversione in Dataset Hugging Face\n",
        "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "\n",
        "print(\"Train set size:\", len(dataset[\"train\"]))\n",
        "print(\"Test set size:\", len(dataset[\"test\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIorN96Pe116",
        "outputId": "d23349ff-5d43-4408-c716-b8d36ab848a4"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 134\n",
            "Test set size: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer Setup and Dataset Tokenization\n",
        "This section prepares the tokenizer and tokenizes the dataset for training with GPT-2.\n",
        "\n",
        "#### **Tokenizer Configuration**\n",
        "- The tokenizer is loaded from the pre-trained `GPT-2` model\n",
        "  - GPT-2 does not have a default padding token, so the EOS (`end-of-sequence`) token is assigned as the padding token.\n",
        "\n",
        "#### **Tokenization Function**\n",
        "- **Input Processing:**\n",
        "  - Each text sample is tokenized using the GPT-2 tokenizer.\n",
        "  - `padding=\"max_length\"` ensures all sequences have a fixed size (`256` tokens) for efficient batch processing.\n",
        "  - `truncation=True` prevents sequences from exceeding the maximum length.\n",
        "  - **Note:** the longest entry in the dataset is 200 token long.\n",
        "\n",
        "#### **Tokenizing the Dataset**\n",
        "- The dataset is processed using `.map()` to apply tokenization to all examples in batches.\n",
        "- The `remove_columns` parameter ensures only the necessary tokenized fields (`input_ids`, `attention_mask`) remain.\n",
        "\n",
        "#### **Final Output**\n",
        "- The `tokenized_datasets` object contains the processed dataset, ready for model training.\n",
        "\n",
        "This setup ensures the dataset is efficiently formatted for fine-tuning GPT-2.\n"
      ],
      "metadata": {
        "id": "7qLaNi6l0jZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"gpt2\"\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_checkpoint)\n",
        "# Imposta un token di padding se non definito\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
        "\n",
        "# Imposta una lunghezza massima\n",
        "max_length = 256\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Ritorna un unico dict con input_ids e attention_mask\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n",
        "\n",
        "tokenized_datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255,
          "referenced_widgets": [
            "27e72ab4e56b4ab29f27560ae6621040",
            "76e8cad32f8445a7a88b7d5873769b2b",
            "f2e80c702c514b3d836eaa296dcf10bd",
            "5a9c61ed4a674ade9e11b16e4171e8de",
            "4ffd946925034d5684ffca188ad61e9c",
            "ccda8dc9b61a4276bd857c943b2e4260",
            "dfbaec8a76a849668568db1a987fcab6",
            "eb6b9e9be6b64c8e8ed723d18e32dc75",
            "d1d21ff0c5934b51a078795cb0ec4f0f",
            "edc54bc9dda44946a6798fd8d301d29e",
            "6b7b46b4b6604d068524206b4991d3d9",
            "361027af7e6f4150b169e76a3582c456",
            "55cbb046b06a42d388c9fabbe99a5b26",
            "cf722fe5d7874faaac527179e21db0f4",
            "9bf9a77ccd084922b10d55c56f4442c8",
            "336f2b09ae22490aaba2fa9b9f8c8997",
            "5165709bbcf043f0abc419884cdad32c",
            "c7130e462740451b828b470419a58b7d",
            "48c189c45af84cb693bb1fc3e00e1230",
            "d4de0272de7a487383ea4f9924446b72",
            "f3c6db1cb63c464a9a6e038cf67dfee8",
            "18537cf95d7f4080a5c3d2ef2d295c31"
          ]
        },
        "id": "xWYQtcfse9ZK",
        "outputId": "82bcfa10-9469-4ae9-d868-eb467cc05fda"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/134 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27e72ab4e56b4ab29f27560ae6621040"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "361027af7e6f4150b169e76a3582c456"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 134\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask'],\n",
              "        num_rows: 34\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Causal Language Modeling\n",
        ")\n"
      ],
      "metadata": {
        "id": "yHGDzgnNfC1I"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#se model esiste\n",
        "if model != None:\n",
        "  del model\n",
        "  torch.cuda.empty_cache()\n",
        "  del tokenizer"
      ],
      "metadata": {
        "id": "1KlzI1b0RJwa"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Aggiungiamo eventuali token se abbiamo aggiunto un token di pad\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50xLv--IfEkJ",
        "outputId": "368c103c-9370-440d-d9f8-662b639c6ff6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50257, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metrics and Text Postprocessing\n",
        "This section defines the evaluation metrics and a helper function to preprocess text for evaluation.\n",
        "\n",
        "#### **Evaluation Metrics**\n",
        "- **ROUGE:** Measures overlap between n-grams, sequences, and longest common subsequences between predictions and references. Ideal for summarization and text generation tasks.\n",
        "- **BLEU:** Evaluates the precision of generated words compared to reference texts, often used for translation tasks.\n",
        "- **METEOR:** Focuses on synonym matching, stemming, and word order, providing a nuanced evaluation for generated text.\n",
        "\n",
        "The metrics are loaded using the `evaluate` library, enabling easy integration into the training and evaluation workflow.\n",
        "\n",
        "#### **Postprocessing Function**\n",
        "- The `postprocess_text` function ensures predictions and references are properly formatted for accurate metric computation:\n",
        "  - **Whitespace Cleanup:** Removes unnecessary spaces from both predictions and labels.\n",
        "  - **Sentence Tokenization:** Segments predictions and references into sentences using NLTK's `sent_tokenize` to align with how ROUGE calculates scores.\n",
        "\n",
        "This preprocessing ensures consistency and improves the reliability of the evaluation metrics.\n"
      ],
      "metadata": {
        "id": "tz4rWFZ91Kqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_score = evaluate.load(\"rouge\")\n",
        "bleu_score  = evaluate.load(\"bleu\")\n",
        "meteor_score = evaluate.load(\"meteor\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    \"\"\"\n",
        "    - Rimuove spazi superflui\n",
        "    - Segmenta in frasi per calcolare ROUGE in modo corretto\n",
        "    \"\"\"\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "    return preds, labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWd2IpvqpW2U",
        "outputId": "a29dd2a9-6200-4f76-bce9-83021da3571f"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Metrics Function for Model Evaluation\n",
        "This function computes **ROUGE**, **BLEU**, and **METEOR** scores to evaluate model-generated text against reference labels.\n",
        "\n",
        "#### **Processing Predictions and Labels**\n",
        "- The function receives model `logits` (raw outputs) and `labels` (ground truth).\n",
        "- **Handling Masked Tokens:**  \n",
        "  - In **GPT-2**, `-100` is not typically used for ignored tokens (as in seq2seq models).\n",
        "  - If present, it is replaced with the tokenizer’s pad token.\n",
        "- **Argmax Decoding:**  \n",
        "  - The highest probability token is selected for each position in the logits.\n",
        "  - The resulting token IDs are converted into human-readable text using `batch_decode()`.\n",
        "\n",
        "#### **Post-Processing**\n",
        "- **Whitespace Cleanup & Sentence Splitting:**  \n",
        "  - Predictions and labels are preprocessed using `postprocess_text()`.\n",
        "  - This ensures proper tokenization for ROUGE and improves metric accuracy.\n",
        "\n",
        "#### **Metric Computation**\n",
        "- **ROUGE:**  \n",
        "  - Measures n-gram overlap between predictions and references.\n",
        "- **BLEU:**  \n",
        "  - `evaluate` requires references in a **list of lists** format (`[[reference]]`).\n",
        "  - Measures word sequence precision against references.\n",
        "- **METEOR:**  \n",
        "  - Considers synonym matching, stemming, and word order for better evaluation.\n",
        "\n",
        "#### **Result Formatting**\n",
        "- Scores are converted to percentages (`*100`) and rounded for readability.\n",
        "- The final dictionary contains:\n",
        "  - **ROUGE-1, ROUGE-2, ROUGE-L** (n-gram and longest common subsequence similarity)\n",
        "  - **BLEU** (precision-based similarity)\n",
        "  - **METEOR** (semantic matching)\n",
        "\n",
        "This function ensures a **comprehensive evaluation** of model-generated text.\n"
      ],
      "metadata": {
        "id": "zv1Wqbgy18te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    #se si usa -100 come padding token lo sostituiamoc con quello usato da gpt-2\n",
        "    labels[labels == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # Argmax sui logits per ottenere la sequenza predetta\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Decodifica in stringhe\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Post-processing (rimozione spazi, split in frasi)\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    # Calcolo delle metriche\n",
        "    # 1) ROUGE\n",
        "    rouge_results = rouge_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels\n",
        "    )\n",
        "    # 2) BLEU\n",
        "    # La metrica BLEU in `evaluate` richiede `references` come lista di liste\n",
        "    bleu_results = bleu_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=[[lbl] for lbl in decoded_labels]\n",
        "    )\n",
        "    # 3) METEOR\n",
        "    meteor_results = meteor_score.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels\n",
        "    )\n",
        "\n",
        "    # Organizza i risultati\n",
        "    result = {}\n",
        "    # ROUGE\n",
        "    result[\"rouge1\"] = round(rouge_results[\"rouge1\"] * 100, 2)\n",
        "    result[\"rouge2\"] = round(rouge_results[\"rouge2\"] * 100, 2)\n",
        "    result[\"rougeL\"] = round(rouge_results[\"rougeL\"] * 100, 2)\n",
        "    # BLEU\n",
        "    result[\"bleu\"] = round(bleu_results[\"bleu\"] * 100, 2)\n",
        "    # METEOR\n",
        "    result[\"meteor\"] = round(meteor_results[\"meteor\"] * 100, 2)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "nzD11TV3fGVX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ARvJpBGkf41b",
        "outputId": "29f9e89e-5aa5-46a1-ebff-688b9b6c9e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Configuration and Trainer Initialization\n",
        "This section configures the training arguments and initializes the `Trainer` for fine-tuning GPT-2 on IFTTT-like tasks.\n",
        "\n",
        "#### **Training Arguments Configuration**\n",
        "- **Output Directory:**  \n",
        "  - Saves model checkpoints in `./gpt2-ifttt`.\n",
        "  - Overwrites existing checkpoints if `overwrite_output_dir=True`.\n",
        "- **Evaluation & Checkpointing Strategy:**  \n",
        "  - `evaluation_strategy=\"epoch\"` → Evaluates the model at the end of each epoch.\n",
        "  - `save_strategy=\"epoch\"` → Saves model checkpoints at the end of each epoch.\n",
        "- **Training Hyperparameters:**  \n",
        "  - `num_train_epochs=30` → Trains for 30 epochs (adjust based on dataset size and performance).\n",
        "  - `per_device_train_batch_size=4` → Processes 4 examples per batch (adjust based on GPU memory).\n",
        "  - `per_device_eval_batch_size=4` → Uses the same batch size for evaluation.\n",
        "- **Logging & Precision:**  \n",
        "  - `logging_steps=50` → Logs progress every 50 steps.\n",
        "  - `fp16=torch.cuda.is_available()` → Uses **mixed precision** (`fp16`) if a compatible GPU is available, improving efficiency.\n",
        "  - `report_to=\"none\"` → Disables logging to external tools like WandB.\n",
        "\n",
        "#### **Trainer Initialization**\n",
        "- The `Trainer` class simplifies training by handling:\n",
        "  - **Model Training & Evaluation:** Uses the specified datasets.\n",
        "  - **Data Collation:** Ensures correct batch formatting using `data_collator`.\n",
        "  - **Tokenization:** Ensures consistency in input processing.\n",
        "  - **Metric Computation:** If `compute_metrics` is provided, the model's performance is evaluated after each epoch.\n",
        "\n",
        "This setup allows for an **automated and structured training process**, including evaluation and checkpointing.\n"
      ],
      "metadata": {
        "id": "lqRz8jua2Rwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/Shareddrives/NLPMODELS/gpt2model-2\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",   # Esegui evaluation alla fine di ogni epoca\n",
        "    #save_strategy=\"epoch\",         # Salva un checkpoint a ogni epoca\n",
        "    num_train_epochs=50,            # Cambia secondo le tue necessità\n",
        "    per_device_train_batch_size=8, # Batch size, adattalo alla tua GPU\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(), # Usa half precision se possibile\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XH_lOb5fH5l",
        "outputId": "a7aa6a64-bd3a-4777-c29f-86e92b44f8d2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-57-0b448a824fdf>:14: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "42zsMe1ofJDf",
        "outputId": "9c687941-3ca9-4597-e8e1-7b4ac37e765f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='850' max='850' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [850/850 06:21, Epoch 50/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Meteor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.689270</td>\n",
              "      <td>41.660000</td>\n",
              "      <td>13.180000</td>\n",
              "      <td>32.590000</td>\n",
              "      <td>23.820000</td>\n",
              "      <td>41.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.304317</td>\n",
              "      <td>45.260000</td>\n",
              "      <td>17.680000</td>\n",
              "      <td>38.790000</td>\n",
              "      <td>5.790000</td>\n",
              "      <td>30.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.693000</td>\n",
              "      <td>2.143444</td>\n",
              "      <td>45.960000</td>\n",
              "      <td>19.460000</td>\n",
              "      <td>39.800000</td>\n",
              "      <td>6.700000</td>\n",
              "      <td>32.830000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.693000</td>\n",
              "      <td>2.030005</td>\n",
              "      <td>47.680000</td>\n",
              "      <td>21.860000</td>\n",
              "      <td>41.830000</td>\n",
              "      <td>6.240000</td>\n",
              "      <td>31.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.693000</td>\n",
              "      <td>1.995079</td>\n",
              "      <td>48.150000</td>\n",
              "      <td>23.390000</td>\n",
              "      <td>42.750000</td>\n",
              "      <td>6.370000</td>\n",
              "      <td>31.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>1.923363</td>\n",
              "      <td>50.130000</td>\n",
              "      <td>24.540000</td>\n",
              "      <td>44.590000</td>\n",
              "      <td>6.110000</td>\n",
              "      <td>31.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>1.904731</td>\n",
              "      <td>51.020000</td>\n",
              "      <td>26.400000</td>\n",
              "      <td>45.620000</td>\n",
              "      <td>6.390000</td>\n",
              "      <td>32.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>1.893408</td>\n",
              "      <td>50.550000</td>\n",
              "      <td>27.140000</td>\n",
              "      <td>46.220000</td>\n",
              "      <td>6.610000</td>\n",
              "      <td>33.180000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.213900</td>\n",
              "      <td>1.887706</td>\n",
              "      <td>50.600000</td>\n",
              "      <td>27.200000</td>\n",
              "      <td>46.800000</td>\n",
              "      <td>6.960000</td>\n",
              "      <td>33.850000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.213900</td>\n",
              "      <td>1.871055</td>\n",
              "      <td>54.270000</td>\n",
              "      <td>30.720000</td>\n",
              "      <td>49.050000</td>\n",
              "      <td>7.270000</td>\n",
              "      <td>34.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.213900</td>\n",
              "      <td>1.921492</td>\n",
              "      <td>52.170000</td>\n",
              "      <td>28.960000</td>\n",
              "      <td>47.970000</td>\n",
              "      <td>7.460000</td>\n",
              "      <td>34.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>1.924574</td>\n",
              "      <td>52.910000</td>\n",
              "      <td>30.300000</td>\n",
              "      <td>48.800000</td>\n",
              "      <td>7.950000</td>\n",
              "      <td>35.960000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>1.941229</td>\n",
              "      <td>51.980000</td>\n",
              "      <td>29.150000</td>\n",
              "      <td>48.090000</td>\n",
              "      <td>7.740000</td>\n",
              "      <td>35.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>1.983793</td>\n",
              "      <td>53.070000</td>\n",
              "      <td>30.210000</td>\n",
              "      <td>49.220000</td>\n",
              "      <td>7.830000</td>\n",
              "      <td>36.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.685200</td>\n",
              "      <td>2.010110</td>\n",
              "      <td>52.740000</td>\n",
              "      <td>31.210000</td>\n",
              "      <td>49.470000</td>\n",
              "      <td>7.790000</td>\n",
              "      <td>36.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.685200</td>\n",
              "      <td>2.064304</td>\n",
              "      <td>53.270000</td>\n",
              "      <td>31.580000</td>\n",
              "      <td>49.550000</td>\n",
              "      <td>7.870000</td>\n",
              "      <td>35.860000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.685200</td>\n",
              "      <td>2.065462</td>\n",
              "      <td>54.110000</td>\n",
              "      <td>31.680000</td>\n",
              "      <td>50.030000</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>36.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.521900</td>\n",
              "      <td>2.090600</td>\n",
              "      <td>53.090000</td>\n",
              "      <td>31.490000</td>\n",
              "      <td>49.490000</td>\n",
              "      <td>8.250000</td>\n",
              "      <td>36.930000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.521900</td>\n",
              "      <td>2.143341</td>\n",
              "      <td>52.790000</td>\n",
              "      <td>30.680000</td>\n",
              "      <td>48.820000</td>\n",
              "      <td>8.330000</td>\n",
              "      <td>36.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.521900</td>\n",
              "      <td>2.164862</td>\n",
              "      <td>53.090000</td>\n",
              "      <td>31.160000</td>\n",
              "      <td>49.390000</td>\n",
              "      <td>9.340000</td>\n",
              "      <td>38.810000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.408300</td>\n",
              "      <td>2.207715</td>\n",
              "      <td>52.980000</td>\n",
              "      <td>30.980000</td>\n",
              "      <td>49.040000</td>\n",
              "      <td>9.220000</td>\n",
              "      <td>39.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.408300</td>\n",
              "      <td>2.220817</td>\n",
              "      <td>52.950000</td>\n",
              "      <td>31.330000</td>\n",
              "      <td>49.490000</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>38.030000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.408300</td>\n",
              "      <td>2.237993</td>\n",
              "      <td>53.530000</td>\n",
              "      <td>31.650000</td>\n",
              "      <td>49.540000</td>\n",
              "      <td>8.060000</td>\n",
              "      <td>36.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.319300</td>\n",
              "      <td>2.282040</td>\n",
              "      <td>54.570000</td>\n",
              "      <td>32.140000</td>\n",
              "      <td>50.320000</td>\n",
              "      <td>8.220000</td>\n",
              "      <td>37.110000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.319300</td>\n",
              "      <td>2.281332</td>\n",
              "      <td>52.720000</td>\n",
              "      <td>31.780000</td>\n",
              "      <td>49.110000</td>\n",
              "      <td>9.310000</td>\n",
              "      <td>38.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.319300</td>\n",
              "      <td>2.327626</td>\n",
              "      <td>53.330000</td>\n",
              "      <td>31.950000</td>\n",
              "      <td>49.310000</td>\n",
              "      <td>9.410000</td>\n",
              "      <td>38.990000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.258400</td>\n",
              "      <td>2.331291</td>\n",
              "      <td>53.770000</td>\n",
              "      <td>32.820000</td>\n",
              "      <td>50.060000</td>\n",
              "      <td>8.700000</td>\n",
              "      <td>37.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.258400</td>\n",
              "      <td>2.357009</td>\n",
              "      <td>53.530000</td>\n",
              "      <td>32.640000</td>\n",
              "      <td>49.660000</td>\n",
              "      <td>8.770000</td>\n",
              "      <td>37.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.258400</td>\n",
              "      <td>2.353942</td>\n",
              "      <td>54.590000</td>\n",
              "      <td>33.220000</td>\n",
              "      <td>50.290000</td>\n",
              "      <td>8.510000</td>\n",
              "      <td>37.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.223200</td>\n",
              "      <td>2.373247</td>\n",
              "      <td>54.100000</td>\n",
              "      <td>32.860000</td>\n",
              "      <td>50.220000</td>\n",
              "      <td>8.440000</td>\n",
              "      <td>37.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.223200</td>\n",
              "      <td>2.369705</td>\n",
              "      <td>54.300000</td>\n",
              "      <td>32.980000</td>\n",
              "      <td>50.260000</td>\n",
              "      <td>8.470000</td>\n",
              "      <td>37.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.223200</td>\n",
              "      <td>2.386303</td>\n",
              "      <td>54.230000</td>\n",
              "      <td>33.710000</td>\n",
              "      <td>50.760000</td>\n",
              "      <td>8.550000</td>\n",
              "      <td>37.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.196900</td>\n",
              "      <td>2.395244</td>\n",
              "      <td>54.290000</td>\n",
              "      <td>32.610000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>8.010000</td>\n",
              "      <td>36.190000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.196900</td>\n",
              "      <td>2.392641</td>\n",
              "      <td>54.570000</td>\n",
              "      <td>33.010000</td>\n",
              "      <td>50.220000</td>\n",
              "      <td>8.720000</td>\n",
              "      <td>38.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.196900</td>\n",
              "      <td>2.409479</td>\n",
              "      <td>54.300000</td>\n",
              "      <td>32.660000</td>\n",
              "      <td>50.170000</td>\n",
              "      <td>9.330000</td>\n",
              "      <td>39.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>2.415819</td>\n",
              "      <td>55.120000</td>\n",
              "      <td>33.720000</td>\n",
              "      <td>50.990000</td>\n",
              "      <td>8.940000</td>\n",
              "      <td>38.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>2.438555</td>\n",
              "      <td>53.850000</td>\n",
              "      <td>32.760000</td>\n",
              "      <td>50.150000</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>39.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.180600</td>\n",
              "      <td>2.437451</td>\n",
              "      <td>54.740000</td>\n",
              "      <td>33.200000</td>\n",
              "      <td>50.710000</td>\n",
              "      <td>9.310000</td>\n",
              "      <td>39.440000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.162100</td>\n",
              "      <td>2.453183</td>\n",
              "      <td>54.360000</td>\n",
              "      <td>33.290000</td>\n",
              "      <td>50.690000</td>\n",
              "      <td>9.350000</td>\n",
              "      <td>39.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.162100</td>\n",
              "      <td>2.437847</td>\n",
              "      <td>54.740000</td>\n",
              "      <td>33.360000</td>\n",
              "      <td>51.060000</td>\n",
              "      <td>9.010000</td>\n",
              "      <td>38.680000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.162100</td>\n",
              "      <td>2.445852</td>\n",
              "      <td>54.450000</td>\n",
              "      <td>33.020000</td>\n",
              "      <td>50.920000</td>\n",
              "      <td>8.840000</td>\n",
              "      <td>38.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.147800</td>\n",
              "      <td>2.482664</td>\n",
              "      <td>54.140000</td>\n",
              "      <td>32.850000</td>\n",
              "      <td>50.460000</td>\n",
              "      <td>9.320000</td>\n",
              "      <td>39.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.147800</td>\n",
              "      <td>2.482882</td>\n",
              "      <td>54.480000</td>\n",
              "      <td>33.380000</td>\n",
              "      <td>50.670000</td>\n",
              "      <td>9.720000</td>\n",
              "      <td>39.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.147800</td>\n",
              "      <td>2.471119</td>\n",
              "      <td>54.490000</td>\n",
              "      <td>33.240000</td>\n",
              "      <td>51.020000</td>\n",
              "      <td>9.690000</td>\n",
              "      <td>39.910000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.136900</td>\n",
              "      <td>2.481307</td>\n",
              "      <td>54.360000</td>\n",
              "      <td>32.750000</td>\n",
              "      <td>50.700000</td>\n",
              "      <td>9.470000</td>\n",
              "      <td>39.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.136900</td>\n",
              "      <td>2.494154</td>\n",
              "      <td>54.200000</td>\n",
              "      <td>32.970000</td>\n",
              "      <td>50.690000</td>\n",
              "      <td>9.540000</td>\n",
              "      <td>39.540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.136900</td>\n",
              "      <td>2.493748</td>\n",
              "      <td>54.640000</td>\n",
              "      <td>33.580000</td>\n",
              "      <td>50.970000</td>\n",
              "      <td>9.540000</td>\n",
              "      <td>39.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>2.489691</td>\n",
              "      <td>54.340000</td>\n",
              "      <td>33.190000</td>\n",
              "      <td>50.670000</td>\n",
              "      <td>9.330000</td>\n",
              "      <td>39.240000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.140200</td>\n",
              "      <td>2.490806</td>\n",
              "      <td>54.670000</td>\n",
              "      <td>33.810000</td>\n",
              "      <td>50.990000</td>\n",
              "      <td>9.420000</td>\n",
              "      <td>39.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.128400</td>\n",
              "      <td>2.489983</td>\n",
              "      <td>54.840000</td>\n",
              "      <td>33.880000</td>\n",
              "      <td>51.000000</td>\n",
              "      <td>9.370000</td>\n",
              "      <td>39.350000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=850, training_loss=0.5849519308875589, metrics={'train_runtime': 381.9196, 'train_samples_per_second': 17.543, 'train_steps_per_second': 2.226, 'total_flos': 875328307200000.0, 'train_loss': 0.5849519308875589, 'epoch': 50.0})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "print(\"Final eval_loss:\", results[\"eval_loss\"])\n",
        "print(\"Perplexity:\", math.exp(results[\"eval_loss\"]))\n"
      ],
      "metadata": {
        "id": "INTOEO_YfKA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "69cfc70d-cf05-4651-d032-5658368bfdf1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final eval_loss: 2.391672372817993\n",
            "Perplexity: 10.931760643771131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ_N_fG9shO0",
        "outputId": "bb98a362-f6f9-42ff-9785-37a95ade436d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_path = \"/content/drive/Shareddrives/NLPMODELS/gpt2model-2/checkpoint-850\"\n",
        "\n",
        "inference_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "inference_tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Pipeline di text generation\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=inference_model,\n",
        "    tokenizer=inference_tokenizer,\n",
        "    pad_token_id=inference_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Esempio di prompt: solo la \"descrizione\"\n",
        "prompt = \"Create an applet that Save new photos from my phone to a Google Cloud folder automatically.\\n###\\n\"\n",
        "\n",
        "results = generator(prompt, max_length=256, num_return_sequences=1)\n",
        "print(results[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "id": "5PdTIGNIfLLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f725f216-cffa-4bdb-aecd-56e27bec0b65"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create an applet that Save new photos from my phone to a Google Cloud folder automatically.\n",
            "###\n",
            "var photo = new Photos.PhotoMyPhoto.PublicPhotoURL  var address = \"https://platform.google.com/PhotoImages/v1/PublicPhotoURL\"    if (photo.length >= 3 || photo[0] == \"New\") {     AndroidMessages.sendAMessage.skip(\"Not an Instagram photo\") }    else {    GoogleMessages.sendAMessage.setMessage(`Its probably not a Google Photos album\") }    } else {   AndroidMessages.sendAMessage.skip(\"Not an Instagram album album\") }  }   else {   AndroidMessages.sendAMessage.setMessage(`Its probably not an Instagram album\") }  }  } else {   GoogleMessages.sendAMessage.skip(\"Image not saved to Google Photos\") }  }\n",
            "###\n",
            "var actualPhotoURL = 'https://platform.google.com/CameraPhotoImages/format/vi'  var albumName = 'Movies'    if (originalPhotoURL < 107 || (original\n"
          ]
        }
      ]
    }
  ]
}