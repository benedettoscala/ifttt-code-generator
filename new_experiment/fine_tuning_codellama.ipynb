{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/benedettoscala/ifttt-code-generator/blob/main/fine_tuning_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Environment Setup and Authentication\n",
    "This section sets up the necessary environment by installing dependencies, importing required libraries, and authenticating with Hugging Face.\n",
    "\n",
    "#### **Dependency Installation**\n",
    "- Several essential libraries are installed:\n",
    "  - `transformers`: Provides pre-trained models and tokenizers.\n",
    "  - `peft`: Enables parameter-efficient fine-tuning techniques.\n",
    "  - `accelerate`: Optimizes training performance on different hardware configurations.\n",
    "  - `trl`: Supports reinforcement learning for transformers.\n",
    "  - `datasets`: Provides easy access to various datasets.\n",
    "  - `sentencepiece`: Required for tokenization of certain models.\n",
    "  - `bitsandbytes`: Enables efficient quantization techniques for large models.\n",
    "  - `rouge_score`: Used for text evaluation.\n",
    "\n",
    "#### **Library Imports**\n",
    "- The script imports key libraries such as:\n",
    "  - `transformers` for model handling.\n",
    "  - `peft` for efficient fine-tuning.\n",
    "  - `torch` for deep learning operations.\n",
    "  - `pandas` for dataset manipulation.\n",
    "  - `datasets` for handling data structures compatible with Hugging Face.\n",
    "\n",
    "#### **Authentication with Hugging Face**\n",
    "- The script retrieves the `HUGGINGFACE_TOKEN` stored in Google Colabâ€™s `userdata`.\n",
    "- It logs into Hugging Face using `huggingface-cli login` to enable access to pre-trained models, datasets, and private repositories.\n",
    "\n",
    "#### **Repository Cloning**\n",
    "- The script clones the GitHub repository `ifttt-code-generator`, which contains the necessary code for the project.\n",
    "- After cloning, it navigates to the repository directory and pulls the latest updates.\n",
    "\n",
    "This setup ensures that all required dependencies are installed, authentication is handled securely, and the latest project files are available for further development.\n"
   ],
   "metadata": {
    "id": "wkopuWNBxpex"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "\n",
    "!pip install transformers==4.36.2\n",
    "!pip install -U peft\n",
    "!pip install -U accelerate\n",
    "!pip install -U trl\n",
    "!pip install datasets==2.16.0\n",
    "!pip install sentencepiece\n",
    "!pip install -U bitsandbytes\n",
    "!pip install rouge_score"
   ],
   "metadata": {
    "id": "0HueuUrz_TeU",
    "ExecuteTime": {
     "end_time": "2025-02-21T14:25:40.293294Z",
     "start_time": "2025-02-21T14:25:04.982568Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:25:43.775897Z",
     "start_time": "2025-02-21T14:25:40.299301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install matplotlib\n",
    "!pip install numpy"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\scala\\miniconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\scala\\miniconda3\\lib\\site-packages (2.2.3)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wvpQWR5pwCGL",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:39.601561Z",
     "start_time": "2025-02-22T14:26:30.791032Z"
    }
   },
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Loem6gt-xOVZ",
    "outputId": "a3494bda-4af2-4f4d-8071-5953711ae322",
    "ExecuteTime": {
     "end_time": "2025-02-21T14:25:53.602854Z",
     "start_time": "2025-02-21T14:25:53.598941Z"
    }
   },
   "source": [
    "#from google.colab import userdata\n",
    "#secret_hf = userdata.get('HUGGINGFACE_TOKEN')\n",
    "#!huggingface-cli login --token $secret_hf"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h7_T1dEsXfWS",
    "outputId": "3e7ec4df-4a20-4ee7-a168-a2a1017e8c54",
    "ExecuteTime": {
     "end_time": "2025-02-22T10:18:42.952392Z",
     "start_time": "2025-02-22T10:18:41.987622Z"
    }
   },
   "source": [
    "!git clone https://github.com/benedettoscala/ifttt-code-generator\n",
    "%cd ifttt-code-generator/\n",
    "!git pull"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scala\\PycharmProjects\\JupyterProject\\ifttt-code-generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ifttt-code-generator' already exists and is not an empty directory.\n",
      "C:\\Users\\scala\\miniconda3\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzQkARHFU2Hl"
   },
   "source": [
    "### Dataset Processing and Tokenization\n",
    "This section loads, cleans, and tokenizes the dataset using the `Mistral-7B-Instruct-v0.2` tokenizer.\n",
    "\n",
    "#### **Tokenizer Setup**\n",
    "- The tokenizer is loaded from Hugging Face using `AutoTokenizer.from_pretrained()`.\n",
    "- If the tokenizer does not have a defined padding token, it is set to the EOS token to ensure proper tokenization.\n",
    "\n",
    "#### **Dataset Loading and Cleaning**\n",
    "- The dataset is loaded from a CSV file (`cleaned_and_combined.csv`).\n",
    "- Missing values and duplicate entries are removed from the `permission_df`filter_code` columns.\n",
    "\n",
    "#### **Tokenization and Length Calculation**\n",
    "- Each text sample is tokenized separately:\n",
    "  - **Description tokens**: Tokenized without truncation to capture full input lengths.\n",
    "  - **Code tokens**: Tokenized separately for length analysis.\n",
    "  - **Combined tokens**: The description and code are concatenated using a separator (`\\n###\\n`), then tokenized.\n",
    "- The tokenized lengths for descriptions, code snippets, and combined text are stored for statistical analysis.\n",
    "\n",
    "#### **Statistical Analysis**\n",
    "- Minimum, maximum, mean, and median token lengths are computed and printed for each category.\n",
    "\n",
    "#### **Visualization**\n",
    "- A histogram is generated to visualize the distribution of token lengths for the combined text.\n",
    "- A reference line is drawn at **512 tokens** to indicate a common model limit.\n",
    "\n",
    "This analysis helps assess whether input sequences fit within model constraints and guide preprocessing decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Carica il tokenizer\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Imposta il pad token se necessario\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Carica il dataset\n",
    "csv_path = \"datasets/new_dataset.csv\"\n",
    "df = pd.read_csv(csv_path)"
   ],
   "metadata": {
    "id": "wUie-51xRoz7",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:43.032100Z",
     "start_time": "2025-02-22T14:26:39.606567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bcd8430e0224183b4dbca061bfe602a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e56dd2771184676abefd0eca37758b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e033f2ec654425194ca60b212f7ea20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "915940e303d74b419758570c526d0234"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "df.dropna()\n",
    "\n",
    "#reset indexes\n",
    "df.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "id": "7QVVg7h5SPDY",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:44.466017Z",
     "start_time": "2025-02-22T14:26:44.449018Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "aJJaQJWxSY5C",
    "outputId": "717abd79-5b90-48c9-ecf9-9528a2dc1ef4",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:45.346548Z",
     "start_time": "2025-02-22T14:26:45.333028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                         permission_df  \\\n",
       "0    if New pink line alert (trigger_service: Chica...   \n",
       "1    if New bus advisory (trigger_service: NJ Trans...   \n",
       "2    if New DART rider alert (trigger_service: DART...   \n",
       "3    if New tweet by a specific user (trigger_servi...   \n",
       "4    if New feed item (trigger_service: RSS Feed) t...   \n",
       "..                                                 ...   \n",
       "610  if Door opened (trigger_service: MyQ) then Act...   \n",
       "611  if You enter an area (trigger_service: Locatio...   \n",
       "612  if You enter an area (trigger_service: Locatio...   \n",
       "613  if You enter an area (trigger_service: Locatio...   \n",
       "614  if Every hour at (trigger_service: Date & Time...   \n",
       "\n",
       "                                           filter_code  \n",
       "0    var Hour = Meta.currentUserTime.hour() var Day...  \n",
       "1    var Hour = Meta.currentUserTime.hour() var Day...  \n",
       "2    var Hour = Meta.currentUserTime.hour() var Day...  \n",
       "3    if (Twitter.newTweetByUser.Text.indexOf(\"SNES\"...  \n",
       "4    if(Feed.newFeedItem.EntryContent.indexOf(\"@\") ...  \n",
       "..                                                 ...  \n",
       "610  var timeOfDay = Meta.currentUserTime.hour()   ...  \n",
       "611  var timeOfDay = Meta.currentUserTime.hour() if...  \n",
       "612  var timeOfDay = Meta.currentUserTime.hour();  ...  \n",
       "613  var timeOfDay = Meta.currentUserTime.hour() if...  \n",
       "614  var hour     = Meta.currentUserTime.hour()  if...  \n",
       "\n",
       "[615 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permission_df</th>\n",
       "      <th>filter_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if New pink line alert (trigger_service: Chica...</td>\n",
       "      <td>var Hour = Meta.currentUserTime.hour() var Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if New bus advisory (trigger_service: NJ Trans...</td>\n",
       "      <td>var Hour = Meta.currentUserTime.hour() var Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if New DART rider alert (trigger_service: DART...</td>\n",
       "      <td>var Hour = Meta.currentUserTime.hour() var Day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if New tweet by a specific user (trigger_servi...</td>\n",
       "      <td>if (Twitter.newTweetByUser.Text.indexOf(\"SNES\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if New feed item (trigger_service: RSS Feed) t...</td>\n",
       "      <td>if(Feed.newFeedItem.EntryContent.indexOf(\"@\") ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>if Door opened (trigger_service: MyQ) then Act...</td>\n",
       "      <td>var timeOfDay = Meta.currentUserTime.hour()   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>if You enter an area (trigger_service: Locatio...</td>\n",
       "      <td>var timeOfDay = Meta.currentUserTime.hour() if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>if You enter an area (trigger_service: Locatio...</td>\n",
       "      <td>var timeOfDay = Meta.currentUserTime.hour();  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>if You enter an area (trigger_service: Locatio...</td>\n",
       "      <td>var timeOfDay = Meta.currentUserTime.hour() if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>if Every hour at (trigger_service: Date &amp; Time...</td>\n",
       "      <td>var hour     = Meta.currentUserTime.hour()  if...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Carica il tokenizer\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Imposta il pad token se necessario\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Carica il dataset\n",
    "csv_path = \"datasets/new_dataset.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Pulizia: rimuovi eventuali righe con valori mancanti o duplicati\n",
    "df.dropna(subset=[\"permission_df\", \"filter_code\"], inplace=True)\n",
    "df.drop_duplicates(subset=[\"permission_df\", \"filter_code\"], inplace=True)\n",
    "\n",
    "# Imposta il separatore usato per combinare descrizione e codice\n",
    "separator = \"\\n###\\n\"\n",
    "\n",
    "# Liste per memorizzare le lunghezze (in token) per ciascun esempio\n",
    "description_lengths = []\n",
    "code_lengths = []\n",
    "combined_lengths = []\n",
    "\n",
    "# Itera sulle righe del dataset e tokenizza\n",
    "for _, row in df.iterrows():\n",
    "    description = row[\"permission_df\"]\n",
    "    code = row[\"filter_code\"]\n",
    "\n",
    "    # Tokenizza la descrizione (senza troncamento, per avere la lunghezza completa)\n",
    "    desc_tokens = tokenizer.encode(description, truncation=False)\n",
    "    # Tokenizza il codice\n",
    "    code_tokens = tokenizer.encode(code, truncation=False)\n",
    "    # Tokenizza il testo completo: descrizione + separatore + codice\n",
    "    combined_text = description + separator + code\n",
    "    combined_tokens = tokenizer.encode(combined_text, truncation=False)\n",
    "\n",
    "    description_lengths.append(len(desc_tokens))\n",
    "    code_lengths.append(len(code_tokens))\n",
    "    combined_lengths.append(len(combined_tokens))\n",
    "\n",
    "# Calcola statistiche per ciascuna serie di lunghezze\n",
    "def print_stats(name, lengths):\n",
    "    print(f\"Statistiche per {name}:\")\n",
    "    print(\"  Min:\", np.min(lengths))\n",
    "    print(\"  Max:\", np.max(lengths))\n",
    "    print(\"  Media:\", np.mean(lengths))\n",
    "    print(\"  Mediana:\", np.median(lengths))\n",
    "    print()\n",
    "\n",
    "print_stats(\"la descrizione\", description_lengths)\n",
    "print_stats(\"il codice\", code_lengths)\n",
    "print_stats(\"il testo completo (descrizione + codice)\", combined_lengths)\n",
    "\n",
    "# Visualizza la distribuzione della lunghezza del testo completo\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(combined_lengths, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(512, color='red', linestyle='dashed', linewidth=2, label=\"512 token\")\n",
    "plt.title(\"Distribuzione della lunghezza dei testi (in token)\")\n",
    "plt.xlabel(\"Numero di token\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "id": "3-0A3go0z_QE",
    "outputId": "ac997a16-6f31-41d6-be12-450e5213bfc2",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:49.275535Z",
     "start_time": "2025-02-22T14:26:48.588773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistiche per la descrizione:\n",
      "  Min: 22\n",
      "  Max: 45\n",
      "  Media: 29.285714285714285\n",
      "  Mediana: 29.0\n",
      "\n",
      "Statistiche per il codice:\n",
      "  Min: 9\n",
      "  Max: 11112\n",
      "  Media: 170.56776556776558\n",
      "  Mediana: 58.0\n",
      "\n",
      "Statistiche per il testo completo (descrizione + codice):\n",
      "  Min: 41\n",
      "  Max: 11141\n",
      "  Media: 202.86813186813185\n",
      "  Mediana: 89.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:25:58.249623Z",
     "start_time": "2025-02-21T14:25:56.046447Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -U scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\scala\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")"
   ],
   "metadata": {
    "id": "_SWl39j5-3iI",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:54.411188Z",
     "start_time": "2025-02-22T14:26:54.349188Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "#funzione per trovare i moduli lineare come detto da quel paper su QLoRA\n",
    "def find_target_modules(model):\n",
    "    # Initialize a Set to Store Unique Layers\n",
    "    unique_layers = set()\n",
    "\n",
    "    # Iterate Over All Named Modules in the Model\n",
    "    for name, module in model.named_modules():\n",
    "        # Check if the Module Type Contains 'Linear4bit'\n",
    "        if \"Linear4bit\" in str(type(module)):\n",
    "            # Extract the Type of the Layer\n",
    "            layer_type = name.split('.')[-1]\n",
    "\n",
    "            # Add the Layer Type to the Set of Unique Layers\n",
    "            unique_layers.add(layer_type)\n",
    "\n",
    "    # Return the Set of Unique Layers Converted to a List\n",
    "    return list(unique_layers)"
   ],
   "metadata": {
    "id": "-96GKQvXYd_m",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:26:56.262619Z",
     "start_time": "2025-02-22T14:26:56.247470Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Loading and LoRA Configuration\n",
    "This section loads the base model, applies 4-bit quantization for memory efficiency, and configures LoRA (Low-Rank Adaptation) for fine-tuning.\n",
    "\n",
    "#### **Model Quantization Setup**\n",
    "- The base model `\"mistralai/Mistral-7B-Instruct-v0.2\"` is selected for fine-tuning.\n",
    "- `BitsAndBytesConfig` is used to enable **4-bit quantization**, which reduces memory consumption while maintaining performance:\n",
    "  - `nf4` (Normal Float 4) is chosen as the quantization type.\n",
    "  - `bfloat16` is used for computations to balance precision and efficiency.\n",
    "  - `bnb_4bit_use_double_quant=False` prevents additional quantization layers to keep training stable.\n",
    "\n",
    "#### **Model and Tokenizer Initialization**\n",
    "- The base model is loaded with the quantization settings and mapped automatically to available hardware (`device_map=\"auto\"`).\n",
    "- The tokenizer is loaded and configured:\n",
    "  - The padding token is set to the EOS token to handle padding properly.\n",
    "  - The padding side is set to `\"left\"` to align inputs correctly for causal language modeling.\n",
    "\n",
    "#### **LoRA Configuration for Efficient Fine-Tuning**\n",
    "- `prepare_model_for_kbit_training()` is applied to disable gradients on frozen quantized layers, optimizing the model for fine-tuning.\n",
    "- **LoRA Parameters:**\n",
    "  - `r=16`: The rank of the LoRA adaptation matrices (higher values increase capacity).\n",
    "  - `lora_alpha=32`: Controls scaling of LoRA updates.\n",
    "  - `lora_dropout=0.05`: Adds dropout regularization to prevent overfitting.\n",
    "  - `bias=\"none\"`: No bias parameters are added.\n",
    "  - `task_type=\"CAUSAL_LM\"`: Specifies the model is a causal language model.\n",
    "  - `target_modules`: LoRA is applied to key transformer components (`q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`), which control attention mechanism computations.\n",
    "\n",
    "#### **Printing Trainable Parameters**\n",
    "- The script prints out the number of trainable parameters after applying LoRA, ensuring only the lightweight LoRA adapters are updated while keeping the main model frozen.\n",
    "\n",
    "This setup enables efficient fine-tuning on large-scale language models with minimal computational overhead.\n"
   ],
   "metadata": {
    "id": "6--FJS_EyJCK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "\n",
    "# Sostituisci con il tuo modello\n",
    "base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "# Configurazione per la quantizzazione 4-bit\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Impostiamo i limiti di memoria massima (indicativi!) per GPU e CPU.\n",
    "# - \"0\": la tua prima GPU (se ne hai solo una).\n",
    "# - \"cpu\": la CPU.\n",
    "#\n",
    "# Ad esempio, se hai una GPU da 12GB o 16GB, puoi regolare la voce \"0\" di conseguenza.\n",
    "# \"cpu\" puÃ² essere anche maggiore (in GB) se hai abbastanza RAM di sistema.\n",
    "max_memory = {\n",
    "    0: \"8GiB\",  # Limite (fittizio) di 10 GiB sulla GPU\n",
    "    \"cpu\": \"16GiB\"  # Limite di 48 GiB sulla CPU\n",
    "}\n",
    "\n",
    "print(\"Caricamento del modello base (con offload su CPU/GPU)...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",         # lascia decidere a HF come piazzare i layer\n",
    "    #max_memory=max_memory      # impone i limiti di memoria\n",
    ")\n",
    "\n",
    "print(\"Caricamento del tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "# Prepara il modello per k-bit training (disabilita i gradienti del modello base)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Configurazione LoRA (puoi ridurre r se serve ulteriore risparmio)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=find_target_modules(model),\n",
    ")\n",
    "\n",
    "print(\"Applicazione di LoRA al modello...\")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "print(\"Parametri allenabili:\")\n",
    "model.print_trainable_parameters()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "c437eda561f4447c81c567b722a296d0",
      "18e561ad37f5470a98e705b26dc18ac4",
      "b261b69fd53945a5b932459123d86741",
      "46bd58fea6774e43b8483dc811d802a3",
      "4c3d1a844df94a739aa62c153d5401f4",
      "70249b8e2e574ef8bb155bb69a4ecc11",
      "f6c6cdd6c9224d66982832f42b2a3452",
      "bf1be2a6419b4d8ab59688c61dc787b9",
      "b457d042d57c48bd9d0e1031788cc148",
      "9de3e491fd044af69e040d4f4ef417f0",
      "93ea97cf18ae437dae889e993eb644df"
     ]
    },
    "id": "26hh2jaO-5pZ",
    "outputId": "95abd170-603e-4c5c-cee5-62b8be8da63d",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:29:29.424477Z",
     "start_time": "2025-02-22T14:27:05.265074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del modello base (con offload su CPU/GPU)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/637 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfc88592f4e54d68bfc5aaa395637844"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "890896490c5d446295740251f5b64586"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1063ff7c9533445b9492eeeec71bfcb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c66e7f676d54ab8838431f375f2dc1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41ce9c116efd49478ef2538504ffc602"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64c4277b694c42928018fff09219ec16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a0053cbbfeb4e88a46a104637d42df6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del tokenizer...\n",
      "Applicazione di LoRA al modello...\n",
      "Parametri allenabili:\n",
      "trainable params: 39,976,960 || all params: 6,778,523,648 || trainable%: 0.5898\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Caricamento e pulizia del dataset\n",
    "csv_path = \"datasets/new_dataset.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df.dropna(subset=[\"permission_df\", \"filter_code\"], inplace=True)\n",
    "\n",
    "#drop duplicates\n",
    "#df.drop_duplicates(subset=[\"permission_df\", \"filter_code\"], inplace=True)\n",
    "\n",
    "#Suddivisione train   e val\n",
    "train_df, eval_df = train_test_split(df, test_size=0.356, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "eval_dataset  = Dataset.from_pandas(eval_df)"
   ],
   "metadata": {
    "id": "ey3NStBN_Bhx",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:30:57.777576Z",
     "start_time": "2025-02-22T14:30:57.748575Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "eval_dataset"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uboU1hT5KTYb",
    "outputId": "73eed79d-24af-4d2c-a285-2f41fd00ebf7",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:30:59.993733Z",
     "start_time": "2025-02-22T14:30:59.987736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['permission_df', 'filter_code', '__index_level_0__'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:26:18.515069Z",
     "start_time": "2025-02-21T14:26:16.235903Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\scala\\miniconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\scala\\miniconda3\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\scala\\miniconda3\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torchvision) (2.2.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\scala\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:26:18.540612Z",
     "start_time": "2025-02-21T14:26:18.535611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print('it works')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it works\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T14:26:20.522823Z",
     "start_time": "2025-02-21T14:26:18.595527Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install bitsandbytes>=0.43.0",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenization and Data Collation\n",
    "This section preprocesses the dataset by tokenizing input sequences and preparing them for training.\n",
    "\n",
    "#### **Tokenization Process**\n",
    "- The function `tokenize_function` processes the dataset by:\n",
    "  1. **Concatenating Descriptions and Code:**  \n",
    "     - A separator (`\\n###\\n`) is used to distinguish between the description and the corresponding code.\n",
    "  2. **Tokenizing the Full Input:**  \n",
    "     - Texts are tokenized with a max length of `256` tokens and padded using `\"max_length\"` to ensure consistent input sizes.\n",
    "  3. **Calculating Prompt Lengths:**  \n",
    "     - The same tokenization settings are applied to the prompt alone (description + separator).\n",
    "     - The number of tokens in the prompt (excluding padding) is recorded.\n",
    "  4. **Creating Labels:**  \n",
    "     - Tokens corresponding to the prompt are masked using `-100` (ignored during loss computation).\n",
    "     - The remaining part (code) is left unchanged for the model to learn from.\n",
    "\n",
    "#### **Dataset Tokenization**\n",
    "- The `train_dataset` and `eval_dataset` are processed using `dataset.map()`, applying the tokenization function in batches.\n",
    "\n",
    "This setup ensures efficient tokenization and dynamic padding, making training more stable and memory-efficient.\n"
   ],
   "metadata": {
    "id": "T0Wuaffcyg6c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "# Funzione di tokenizzazione\n",
    "def tokenize_function(examples):\n",
    "    separator = \"\\n###\\n\"\n",
    "\n",
    "    # Concateno desc + code\n",
    "    full_text = [\n",
    "        desc + separator + code\n",
    "        for desc, code in zip(examples[\"permission_df\"], examples[\"filter_code\"])\n",
    "    ]\n",
    "\n",
    "    # Tokenizza con padding e truncation \"coerenti\"\n",
    "    tokenized = tokenizer(\n",
    "        full_text,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\"  # cosi ottengo shape costanti\n",
    "    )\n",
    "\n",
    "    # Calcolo la lunghezza del prompt con gli stessi identici parametri\n",
    "    prompt_text = [\n",
    "        desc + separator\n",
    "        for desc in examples[\"permission_df\"]\n",
    "    ]\n",
    "    tokenized_prompt = tokenizer(\n",
    "        prompt_text,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\"  # stesse impostazioni\n",
    "    )\n",
    "    prompt_lengths = [\n",
    "        sum(p_id != tokenizer.pad_token_id for p_id in p_ids)\n",
    "        for p_ids in tokenized_prompt[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    # Costruisco le label: maschero la parte del prompt con -100\n",
    "    labels = []\n",
    "    for i, seq in enumerate(tokenized[\"input_ids\"]):\n",
    "        prompt_len = prompt_lengths[i]\n",
    "        # Il prompt Ã¨ su N token e la rimanente parte su (512 - N) token\n",
    "        masked_labels = [-100]*prompt_len + seq[prompt_len:]\n",
    "        labels.append(masked_labels)\n",
    "\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "eval_dataset  = eval_dataset.map(tokenize_function,  batched=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "8d88ee5e4ad34ec680f273746d397875",
      "5f85385a9f864695b2d14603b973cb4c",
      "cec59ec9b17549e5934749c05c400d93",
      "fd9da883fdba4c9fab45f3431c65e745",
      "8cbc76e2623f41469385ff3c3c693559",
      "c94dbdd94406423988524e253cdb5534",
      "15eea73691dc4e3bba10f624e94d9b5f",
      "0750ee95c9964c3c88ae4d6b887e7fb0",
      "542162c2fb714319a6e1fe3ec2539b7b",
      "e45d1ed9136c48a2939625ceff0aada3",
      "e963bb217855411eb5514d2b4d019a55",
      "bb3afb5139134c578160917ae8098714",
      "f682f21acb8643c990104c4222048552",
      "91c6f9df2f1e48f699db299de91c0b10",
      "2ffa1a324eb54078813c331a0b919a53",
      "f90493d58e47402eae30c24f049006c4",
      "07e968b158ed47528b51e833deb8e473",
      "2aecadcdb8134f2c9a60bd450e6fe53e",
      "c81817ef70c94c55a64328b63ec857fe",
      "dd94266bae134d61ab1096d9ca487448",
      "f71aad6897bc401089c349f5f18ec48b",
      "b2308da1975f4d1b8c3c2bedab72463b"
     ]
    },
    "id": "iOCFKwkm_Jyx",
    "outputId": "72bb0fdd-28f1-4fa4-a7ff-61234414b1db",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:31:05.856406Z",
     "start_time": "2025-02-22T14:31:04.736160Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/360 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b012759b3fa44c59ef9804de4dee99c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a218be62f9d4af5ae72ef60a8064067"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "id": "vyRtjlC-MEcu",
    "outputId": "00781bef-99ef-40ef-9b92-9b890f2fbfa7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-02-22T14:31:08.310090Z",
     "start_time": "2025-02-22T14:31:07.786361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DaisLabTBB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RnqYjkmBAUp8",
    "outputId": "e37409ce-a140-4400-c0c4-e1ccf4b11fb3",
    "ExecuteTime": {
     "end_time": "2025-02-21T14:26:27.677750Z",
     "start_time": "2025-02-21T14:26:24.771169Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seq2Seq Training Setup with Custom Metrics\n",
    "This section configures and executes the training process using the `Trainer` API with custom evaluation metrics.\n",
    "\n",
    "#### **Training Arguments Configuration**\n",
    "- The `TrainingArguments` class is used to define key training parameters:\n",
    "  - **Training epochs:** `5` full passes over the dataset.\n",
    "  - **Batch size:** `2` per device with `gradient_accumulation_steps=4` to simulate a larger batch.\n",
    "  - **Learning rate:** `1e-4` with a `cosine` scheduler for gradual decay.\n",
    "  - **Weight decay:** `0.01` for regularization.\n",
    "  - **Mixed precision:** `bf16=True` for optimized training on supported GPUs.\n",
    "  - **Evaluation strategy:** `epoch`, meaning evaluation occurs at the end of each epoch.\n",
    "  - **Checkpointing:** Saves model checkpoints every `100` steps, keeping the last `3` checkpoints.\n",
    "\n",
    "#### **Custom Metric Computation**\n",
    "- The `compute_metrics` function evaluates model performance using:\n",
    "  - **BLEU Score:** Measures word overlap between predictions and references, using smoothing for short sentences.\n",
    "  - **METEOR Score:** Accounts for synonyms, stemming, and word order to evaluate translations.\n",
    "  - **ROUGE Score:** Compares n-gram matches between generated and reference texts.\n",
    "- **Key Preprocessing Steps:**\n",
    "  - Converts `-100` labels (ignored during training) into the tokenizer's padding token.\n",
    "  - Decodes predictions and references into readable text before evaluation.\n",
    "  - Computes and averages scores across all samples.\n",
    "\n",
    "#### **Trainer Initialization**\n",
    "- The `Trainer` API is used to manage training:\n",
    "  - The model is fine-tuned on `train_dataset` and evaluated on `eval_dataset`.\n",
    "  - The tokenizer is provided for text processing.\n",
    "  - The `compute_metrics` function is integrated to track performance.\n",
    "\n",
    "#### **Training Execution and Model Saving**\n",
    "- The model training is initiated with `trainer.train()`.\n",
    "- The final fine-tuned model, including **LoRA adapters and quantization settings**, is saved to `\"./results/best_model\"`.\n"
   ],
   "metadata": {
    "id": "_dXXAtp2y4tj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Impostazioni di training specifiche per Seq2Seq\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../NLPMODELS/codellama\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=1.0,\n",
    "    #save_steps=100,\n",
    "    logging_steps=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    #eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    save_total_limit=3,\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    #report_to=\"wandb\",\n",
    "    #predict_with_generate=True\n",
    ")\n",
    "\n",
    "# Funzione per il calcolo delle metriche\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # Se predictions Ã¨ un tuple, prendiamo la prima parte\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    # Se predictions Ã¨ un tensor, trasformiamolo in numpy\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        predictions = predictions.detach().cpu().numpy()\n",
    "\n",
    "    # Se i predictions contengono logits invece di id di token, facciamo argmax\n",
    "    if predictions.dtype not in [int, 'int32', 'int64']:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "    # Decodifica\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Calcolo metriche BLEU, METEOR, ROUGE ecc.\n",
    "    from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "    from nltk.translate.meteor_score import meteor_score\n",
    "    from rouge_score import rouge_scorer\n",
    "\n",
    "    # BLEU\n",
    "    bleu_scores = [\n",
    "        sentence_bleu(\n",
    "            [ref.split()], pred.split(),\n",
    "            smoothing_function=SmoothingFunction().method1\n",
    "        )\n",
    "        for pred, ref in zip(decoded_preds, decoded_labels)\n",
    "    ]\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "    # METEOR\n",
    "    meteor_scores = [\n",
    "        meteor_score([ref.split()], pred.split())\n",
    "        for pred, ref in zip(decoded_preds, decoded_labels)\n",
    "    ]\n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "    # ROUGE\n",
    "    rouge = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    rouge_scores = [\n",
    "        rouge.score(ref, pred)\n",
    "        for pred, ref in zip(decoded_preds, decoded_labels)\n",
    "    ]\n",
    "    avg_rouge1 = sum(score[\"rouge1\"].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
    "    avg_rouge2 = sum(score[\"rouge2\"].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
    "    avg_rougeL = sum(score[\"rougeL\"].fmeasure for score in rouge_scores) / len(rouge_scores)\n",
    "\n",
    "    return {\n",
    "        \"bleu\": avg_bleu,\n",
    "        \"meteor\": avg_meteor,\n",
    "        \"rouge1\": avg_rouge1,\n",
    "        \"rouge2\": avg_rouge2,\n",
    "        \"rougeL\": avg_rougeL,\n",
    "    }\n",
    "\n",
    "# Creazione Seq2SeqTrainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Avvia il training\n",
    "trainer.train()\n",
    "\n",
    "# Salvataggio finale LoRA + quantization\n",
    "trainer.save_model(\"./results/best_model\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309,
     "referenced_widgets": [
      "8eee8b7275f044eb94cce31e2192fe65",
      "6bd2079832b94535aa30c5bac166cbac",
      "bf9e200ce79c4ad2810799292a628002",
      "2741cbeec5554b5b906f6a5e5b7b74a1",
      "0c96dff48d8f4a1582e9f7019db325fa",
      "2ccd442740c3411380511bd74e8ef4b0",
      "6a00cafa70894e72827764f68cd2b1e0",
      "53eed4940eb949acb1f1f9dcb18b67c5"
     ]
    },
    "id": "A1A5paYQ_N7I",
    "outputId": "c24daeae-1a81-4087-d224-b546ae265b6a",
    "ExecuteTime": {
     "end_time": "2025-02-22T14:52:34.281613Z",
     "start_time": "2025-02-22T14:31:30.384379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "C:\\Users\\DaisLabTBB\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='185' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [185/225 20:49 < 04:33, 0.15 it/s, Epoch 4.09/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.628200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.430200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.650700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.287200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.167700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.244800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.883800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.827400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.615300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.485200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.672800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.418100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.297800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.417800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.848800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.278600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.363700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.353100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.308200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.311200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.277100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.161900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.209100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.173400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.167800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.217700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.151800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.211200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.462600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.466600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.461600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.128800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.209000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.220100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.111600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.155700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.073900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.116400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.070100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.074200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DaisLabTBB\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\DaisLabTBB\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\DaisLabTBB\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "C:\\Users\\DaisLabTBB\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_dynamo\\eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 106\u001B[0m\n\u001B[0;32m     96\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m     97\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m     98\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    102\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[0;32m    103\u001B[0m )\n\u001B[0;32m    105\u001B[0m \u001B[38;5;66;03m# Avvia il training\u001B[39;00m\n\u001B[1;32m--> 106\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Salvataggio finale LoRA + quantization\u001B[39;00m\n\u001B[0;32m    109\u001B[0m trainer\u001B[38;5;241m.\u001B[39msave_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results/best_model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:2241\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   2239\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[0;32m   2240\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2242\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2246\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:2548\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2541\u001B[0m context \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   2542\u001B[0m     functools\u001B[38;5;241m.\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mno_sync, model\u001B[38;5;241m=\u001B[39mmodel)\n\u001B[0;32m   2543\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch_samples) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   2544\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m!=\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED\n\u001B[0;32m   2545\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m contextlib\u001B[38;5;241m.\u001B[39mnullcontext\n\u001B[0;32m   2546\u001B[0m )\n\u001B[0;32m   2547\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[1;32m-> 2548\u001B[0m     tr_loss_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2550\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   2551\u001B[0m     args\u001B[38;5;241m.\u001B[39mlogging_nan_inf_filter\n\u001B[0;32m   2552\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[0;32m   2553\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39misnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch\u001B[38;5;241m.\u001B[39misinf(tr_loss_step))\n\u001B[0;32m   2554\u001B[0m ):\n\u001B[0;32m   2555\u001B[0m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[0;32m   2556\u001B[0m     tr_loss \u001B[38;5;241m=\u001B[39m tr_loss \u001B[38;5;241m+\u001B[39m tr_loss \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_globalstep_last_logged)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\trainer.py:3740\u001B[0m, in \u001B[0;36mTrainer.training_step\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m   3737\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mdistributed_type \u001B[38;5;241m==\u001B[39m DistributedType\u001B[38;5;241m.\u001B[39mDEEPSPEED:\n\u001B[0;32m   3738\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscale_wrt_gas\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 3740\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccelerator\u001B[38;5;241m.\u001B[39mbackward(loss, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   3742\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mdetach()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\accelerate\\accelerator.py:2329\u001B[0m, in \u001B[0;36mAccelerator.backward\u001B[1;34m(self, loss, **kwargs)\u001B[0m\n\u001B[0;32m   2327\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlomo_backward(loss, learning_rate)\n\u001B[0;32m   2328\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2329\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: zip the results folder\n",
    "\n",
    "!zip -r results.zip results\n"
   ],
   "metadata": {
    "id": "nk92oMg64PIC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt: empty gpu memory\n",
    "\n",
    "import torch\n",
    "\n",
    "# Empty GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optionally, check GPU memory usage after emptying the cache\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ],
   "metadata": {
    "id": "KN-ZQJOw4eTQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test del Modello"
   ],
   "metadata": {
    "id": "JlZq6yy0xsAZ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import os\n",
    "import torch\n",
    "# Percorso del modello fine-tunato\n",
    "finetuned_model_path = \"./results/best_model\"\n",
    "basemodel_path = \"codellama/CodeLlama-7b-hf\"\n",
    "# Caricamento del modello base\n",
    "\n",
    "\n",
    "#create offload directory if it doesn't exist\n",
    "if not os.path.exists(\"../offload\"):\n",
    "    os.makedirs(\"../offload\")\n",
    "\n",
    "\n",
    "# Caricamento del modello e del tokenizer fine-tunati\n",
    "print(\"Caricamento del modello fine-tunato...\")\n",
    "from peft import PeftModel\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    basemodel_path,\n",
    "    torch_dtype=torch.float16,         # or torch.bfloat16, depending on your setup\n",
    "    quantization_config=bnb_config,           # 4-bit quantization\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"./offload\"         # <= Provide a folder path\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    finetuned_model_path,\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n"
   ],
   "metadata": {
    "id": "Gt6wRWM9Ip2a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "# Funzione per generare il codice IFTTT\n",
    "def generate_ifttt_code(prompt, max_length=512, num_return_sequences=1):\n",
    "    # Tokenizzazione dell'input\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generazione del codice\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        temperature=1,\n",
    "    )\n",
    "\n",
    "    # Decodifica del risultato\n",
    "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return decoded_outputs\n",
    "\n",
    "# Prompt per generare il codice IFTTT\n",
    "prompt = \"Create an IFTTT applet that sends me a push notification every time i upload something on google drive.\"\n",
    "generated_code = generate_ifttt_code(prompt)\n",
    "\n",
    "# Stampa del codice generato\n",
    "print(\"\\nCodice IFTTT generato:\")\n",
    "for i, code in enumerate(generated_code, 1):\n",
    "    print(f\"{code}\")\n"
   ],
   "metadata": {
    "id": "nr950ogTIl_A"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c437eda561f4447c81c567b722a296d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18e561ad37f5470a98e705b26dc18ac4",
       "IPY_MODEL_b261b69fd53945a5b932459123d86741",
       "IPY_MODEL_46bd58fea6774e43b8483dc811d802a3"
      ],
      "layout": "IPY_MODEL_4c3d1a844df94a739aa62c153d5401f4"
     }
    },
    "18e561ad37f5470a98e705b26dc18ac4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70249b8e2e574ef8bb155bb69a4ecc11",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f6c6cdd6c9224d66982832f42b2a3452",
      "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
     }
    },
    "b261b69fd53945a5b932459123d86741": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf1be2a6419b4d8ab59688c61dc787b9",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b457d042d57c48bd9d0e1031788cc148",
      "value": 2
     }
    },
    "46bd58fea6774e43b8483dc811d802a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9de3e491fd044af69e040d4f4ef417f0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_93ea97cf18ae437dae889e993eb644df",
      "value": "â€‡2/2â€‡[01:14&lt;00:00,â€‡34.02s/it]"
     }
    },
    "4c3d1a844df94a739aa62c153d5401f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70249b8e2e574ef8bb155bb69a4ecc11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6c6cdd6c9224d66982832f42b2a3452": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf1be2a6419b4d8ab59688c61dc787b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b457d042d57c48bd9d0e1031788cc148": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9de3e491fd044af69e040d4f4ef417f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93ea97cf18ae437dae889e993eb644df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d88ee5e4ad34ec680f273746d397875": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5f85385a9f864695b2d14603b973cb4c",
       "IPY_MODEL_cec59ec9b17549e5934749c05c400d93",
       "IPY_MODEL_fd9da883fdba4c9fab45f3431c65e745"
      ],
      "layout": "IPY_MODEL_8cbc76e2623f41469385ff3c3c693559"
     }
    },
    "5f85385a9f864695b2d14603b973cb4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c94dbdd94406423988524e253cdb5534",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_15eea73691dc4e3bba10f624e94d9b5f",
      "value": "Map:â€‡100%"
     }
    },
    "cec59ec9b17549e5934749c05c400d93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0750ee95c9964c3c88ae4d6b887e7fb0",
      "max": 360,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_542162c2fb714319a6e1fe3ec2539b7b",
      "value": 360
     }
    },
    "fd9da883fdba4c9fab45f3431c65e745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e45d1ed9136c48a2939625ceff0aada3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e963bb217855411eb5514d2b4d019a55",
      "value": "â€‡360/360â€‡[00:00&lt;00:00,â€‡378.74â€‡examples/s]"
     }
    },
    "8cbc76e2623f41469385ff3c3c693559": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c94dbdd94406423988524e253cdb5534": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15eea73691dc4e3bba10f624e94d9b5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0750ee95c9964c3c88ae4d6b887e7fb0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "542162c2fb714319a6e1fe3ec2539b7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e45d1ed9136c48a2939625ceff0aada3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e963bb217855411eb5514d2b4d019a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb3afb5139134c578160917ae8098714": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f682f21acb8643c990104c4222048552",
       "IPY_MODEL_91c6f9df2f1e48f699db299de91c0b10",
       "IPY_MODEL_2ffa1a324eb54078813c331a0b919a53"
      ],
      "layout": "IPY_MODEL_f90493d58e47402eae30c24f049006c4"
     }
    },
    "f682f21acb8643c990104c4222048552": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07e968b158ed47528b51e833deb8e473",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2aecadcdb8134f2c9a60bd450e6fe53e",
      "value": "Map:â€‡100%"
     }
    },
    "91c6f9df2f1e48f699db299de91c0b10": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c81817ef70c94c55a64328b63ec857fe",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd94266bae134d61ab1096d9ca487448",
      "value": 200
     }
    },
    "2ffa1a324eb54078813c331a0b919a53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f71aad6897bc401089c349f5f18ec48b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b2308da1975f4d1b8c3c2bedab72463b",
      "value": "â€‡200/200â€‡[00:00&lt;00:00,â€‡357.56â€‡examples/s]"
     }
    },
    "f90493d58e47402eae30c24f049006c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07e968b158ed47528b51e833deb8e473": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aecadcdb8134f2c9a60bd450e6fe53e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c81817ef70c94c55a64328b63ec857fe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd94266bae134d61ab1096d9ca487448": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f71aad6897bc401089c349f5f18ec48b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2308da1975f4d1b8c3c2bedab72463b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8eee8b7275f044eb94cce31e2192fe65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "VBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bd2079832b94535aa30c5bac166cbac",
       "IPY_MODEL_bf9e200ce79c4ad2810799292a628002"
      ],
      "layout": "IPY_MODEL_2741cbeec5554b5b906f6a5e5b7b74a1"
     }
    },
    "6bd2079832b94535aa30c5bac166cbac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "LabelModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c96dff48d8f4a1582e9f7019db325fa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2ccd442740c3411380511bd74e8ef4b0",
      "value": "Waiting for wandb.init()...\r"
     }
    },
    "bf9e200ce79c4ad2810799292a628002": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a00cafa70894e72827764f68cd2b1e0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_53eed4940eb949acb1f1f9dcb18b67c5",
      "value": 1
     }
    },
    "2741cbeec5554b5b906f6a5e5b7b74a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c96dff48d8f4a1582e9f7019db325fa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ccd442740c3411380511bd74e8ef4b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a00cafa70894e72827764f68cd2b1e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53eed4940eb949acb1f1f9dcb18b67c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
